<!DOCTYPE HTML>
<html>
<head>
  <meta charset="utf-8">
  
  <title>Decompiling x86 Deep Neural Network Executables | 春秋一语</title>
  <meta name="author" content="Zijian">
  
  <meta name="description" content="Decompiling x86 Deep Neural Network ExecutablesZhibo Liu, The Hong Kong University of Science and Technology
AbstractThey present BTD (Bin to DNN), a ">
  
  
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">

  <meta property="og:title" content="Decompiling x86 Deep Neural Network Executables"/>
  <meta property="og:site_name" content="春秋一语"/>

  
    <meta property="og:image" content=""/>
  

  
  
    <link href="/favicon.png" rel="icon">
  

  <!-- CSS -->
  <link rel="stylesheet" href="/css/themes/journal.css" media="screen" type="text/css">
  <link rel="stylesheet" href="/css/font-awesome.css" media="screen" type="text/css">
  <link rel="stylesheet" href="/css/style.css" media="screen" type="text/css">
  <link rel="stylesheet" href="/css/responsive.css" media="screen" type="text/css">
  <link rel="stylesheet" href="/css/highlight.css" media="screen" type="text/css">
  <link rel="stylesheet" href="/css/highlight-default.min.css" media="screen" type="text/css">
  <link rel="stylesheet" href="/css/google-fonts.css" media="screen" type="text/css">
  <link rel="stylesheet" href="/css/comment.css" media="screen" type="text/css">
  <!--[if lt IE 9]>
    <script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script>
	<script src="https://cdnjs.cloudflare.com/ajax/libs/es5-shim/4.5.9/es5-shim.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/es5-shim/4.5.7/es5-sham.min.js"></script>
  <![endif]-->

  <script src="/js/jquery-2.0.3.min.js"></script>
  
    <script src="/js/marked.js"></script>
    <script src="/js/comment.js"></script>
    <script src="/js/timeago.min.js"></script>
    <script src="/js/highlight.min.js"></script>
	<script src="/js/spin.min.js"></script>
  
  <!-- analytics -->
  



<meta name="generator" content="Hexo 6.3.0"></head>

<body>
  <nav id="main-nav" class="navbar  navbar-default navbar-fixed-top" role="navigation">
    <div class="container">
      <button type="button" class="navbar-header navbar-toggle" data-toggle="collapse" data-target=".navbar-collapse">
	<span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
       <a class="navbar-brand" href="/">春秋一语</a>
      <div class="collapse navbar-collapse nav-menu">
		<ul class="nav navbar-nav">
		  
		  <li>
			<a href="/archives" title="All the articles.">
			  <i class="fa fa-archive"></i>Archives
			</a>
		  </li>
		  
		  <li>
			<a href="/categories" title="All the categories.">
			  <i class="fa fa-folder"></i>Categories
			</a>
		  </li>
		  
		  <li>
			<a href="/tags" title="All the tags.">
			  <i class="fa fa-tags"></i>Tags
			</a>
		  </li>
		  
		  <li>
			<a href="/about" title="About me.">
			  <i class="fa fa-user"></i>About
			</a>
		  </li>
		  
		</ul>
      </div>
    </div> <!-- container -->
</nav>
<div class="clearfix"></div>

  <div class="container">
    <div class="content">
      


	
		<div class="page-header ">		
			<h1 class="title "> Decompiling x86 Deep Neural Network Executables</h1>
		</div>		
	






<div class="row post">
	<!-- cols -->
	
	<div id="top_meta"></div>
	<div class="col-md-9">
	

	<!-- content -->
	<div class="mypage">		
	  		

	  <h1 id="Decompiling-x86-Deep-Neural-Network-Executables"><a href="#Decompiling-x86-Deep-Neural-Network-Executables" class="headerlink" title="Decompiling x86 Deep Neural Network Executables"></a>Decompiling x86 Deep Neural Network Executables</h1><p>Zhibo Liu, The Hong Kong University of Science and Technology</p>
<h2 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h2><p>They present BTD (Bin to DNN), a decompiler for DNN executables. BTD takes DNN executables and outputs full model specifications, including types of DNN operators, network topology, dimensions, and parameters that are (nearly) identical to those of the input models. <strong>Supports different DL compilers and with full optimizations enabled on x86 platforms.</strong></p>
<p><strong>Employs learning-based techniques to infer DNN operators, dynamic analysis to reveal network architectures, and symbolic execution to facilitate inferring dimensions and parameters of DNN operators.</strong></p>
<p>BTD enables accurate recovery of full specifications of complex DNNs with millions of parameters (e.g., ResNet). The recivered DNN specifications can be re-compiled into a new DNN executable exhibiting identical behavior to the input executable.</p>
<p>They also demonstrate cross-architecture legacy code reuse using BTD, and envision BTD being used for other critical downstream tasks like DNN security hardening and patching.</p>
<h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><p>A DL compiler takes a high-level model specification (e.g., in ONNX format) and generates corresponding low-level optimized binary code for a variety of hardware backends (from cloud servers to embedded devices, GPUs, CPUs, and FPGAs).</p>
<p>Compilation of high-level models into binary code typically involves multiple optimization cycles. DL compiler can optimize code utilizing domain-specific hardware features and abstractions. However, they observe that different low-level representaions of the same DNN operator in executables generally retain invariant high-level semantics, as DNN operators like ReLU and Sigmoid, are mathematically defined in a rigorous manner.</p>
<p>They proposed a three-step approach for full recovery of DNN operators, network topology, dimensions, and parameters.</p>
<ul>
<li>BTD conducts representation learning over disassembler-emitted assembly code to classify assembly functions as DNN operators, such as convolution layers (Conv).</li>
<li>Dynamic analysis is then used to chain DNN operators together, thus recovering their topological connectivity.</li>
<li><p>To further recover dimensions and parameters of certain DNN operators (e.g., Conv), they launch trace-based symbolic execution to generate symbolic constraints, primarily over floating-point-related computations. The human-readable symbolic constraints denote semantics of corresponding DNN operators that are invariant across different compilation settings. To deliver an automated pipeline, they then define patterns over symbolic constraints to automatically recover dimensions and memory layouts of parameters. They incorporate taint analysis to largely reduce the cost of symbolic execution which is more heavy weight.</p>
</li>
<li><p>BTD is scalable to recover DNN models from 65 DNN executables, including nearly 3 million instructions, in 60 hours with negligible errors.</p>
</li>
<li><p>Moreover, to demonstrate BTD’s correctness, they rebuild decompiled model specifications with PyTroch. The results show that almost all decompiled DNN models can be recompiled into new executables that behave identically to the reference executables. </p>
</li>
</ul>
<h2 id="Preliminary"><a href="#Preliminary" class="headerlink" title="Preliminary"></a>Preliminary</h2><p><strong>DNN Compiler Frontend: Graph IRs and Optimizations.</strong> Convert DNN computation graphs into graph IRs. Graph IRs specify high-level inputs and outputs of each operator, but do not restrict how each operator is implemented.<br>Transformation and optimization of computation grpahs (IRs).</p>
<p><strong>DNN Compiler Backend: Low-Level IRs and Optimizations.</strong> Graph IR operators can be converted into low-level linear algebra operators. For example, a fully connected (FC) operator can be representated as matrix multiplication followed be addition. Low-level IRs are usually memory related. Hence, optimizations at this step can include hardware intrinsic (固有的) mapping, memory allocation, loop-related optimizations, and parallelization.<br>Transformation and optimization of low-level linear algebra operators.</p>
<p><strong>DNN Compiler Backend: Scheduling and Tuning.</strong> Policies mapping an operator to low-level code are called <em>schedules</em>. </p>
<p><strong>DNN Compiler Backend: Code Gen.</strong> When generating machine code, a DNN operator (or several fused operators) is typically compiled into an individual assembly function. </p>
<h2 id="Decompiling-DNN-Executables"><a href="#Decompiling-DNN-Executables" class="headerlink" title="Decompiling DNN Executables"></a>Decompiling DNN Executables</h2><p><strong>Definition.</strong> The full specifications include: (1) DNN operators(e.g., ReLU, Pooling, and Conv) and their topological connectivity, (2) dimensions of each DNN operator, such as #channels in Conv, and (3) parameters of each DNN operator, such as weights and biases, which are important configurations learned during model training.</p>
<p><strong>Comparison with C/C++ Decompilation.</strong></p>
<ul>
<li>Statements vs. Higher-Level Semantics: Software decompilation line-by-line translates machine instructions into C/C++ statements. </li>
<li>Common Uncertainty: There is no fixed mapping between C/C++ statements and assembly instructions. DL compilers may adopt different optimizations for compiling the same DNN operators. The compiled code may exhibit distinct syntactic forms. Nevertheless, the semantics of DNN operators are retained.</li>
<li>End Goal: Software decompilation is fundamentally undecidable, and decompiled C/C++ code mainly aids (human-based) analysis and comprehension, not recompilation. Besides helping (human-based) comprehension, BTD boosts model reuse, migration, security hardening, and adversarial attacks.</li>
</ul>
<p>NN的反编译主要是一个分类问题，C/C++的反编译是生成问题。 </p>
<p><strong>Opacity in DNN Executables.</strong> </p>
<p>Different compilers and optimizations can result in complex and distinct machine code realizations. </p>
<p><strong>Design Focus.</strong> BTD is designed to process common DNN models compiled by standard DL compilers. </p>
<h2 id="Design"><a href="#Design" class="headerlink" title="Design"></a>Design</h2><p>Deduce high-level model specifications from low-level instructions. </p>
<p>We advocate DL decompilers to satisfy the following criteria:</p>
<ul>
<li><strong>R1 (Generalizability):</strong> Avoid brittle assumptions. Generalize across compilers, optimizations, and versions.</li>
<li><strong>R2 (Correctness):</strong> Use effective, resilient methods and produce correct outputs.</li>
<li><strong>R3 (Performance):</strong> Be efficient when necessary.</li>
<li><strong>R4 (Automation):</strong> Avoid manual analysis and automate the decompilation process.</li>
</ul>
<h4 id="Workflow"><a href="#Workflow" class="headerlink" title="Workflow"></a>Workflow</h4><p>(1) Learning-based techniques for recognizing assembly function as DNN operators like Conv.</p>
<p>(2) Reconstruct the network topology using dynamic analysis.</p>
<p>(3) Use trace-based symbolic execution to extract operator semantics from assembly code and then recover dimensions and parameters with semantics-based patterns. Some operators are too costly for symbolic execution to analyze. They use taint analysis to keep only tainted sub-traces for more expensive symbolic execution to analyze.</p>
<p>(4) BTD produces model specifications that behave identically to original models. BTD does not guarantee 100% correct outputs. Procedures users can follow to fix errors.</p>
<ul>
<li><p><strong>Type I</strong> operators, including activation functions like ReLU and element-wise arithmetic operators, do not ship with parameters; recovering their dimensions is trivial.</p>
</li>
<li><p><strong>Type II and III</strong> operators require dimensions or parameters, such as Polling’s stride <em>S</em> and kernel size <em>K</em>.</p>
</li>
<li><p><strong>Type IV</strong> operators require both parameters and dimensions.</p>
</li>
</ul>
<p><strong>Compilation Provenance.</strong> (1) which DL compiler is used, and (2) whether e is compiled with full optimization -O3 or no optimization -O0. The authors extend their learning-based method to predict compilation provenance from assembly code.</p>
<p>Some patterns are designed separately for Glow- and TVM-emitted executables.</p>
<h3 id="DNN-Operator-Recovery"><a href="#DNN-Operator-Recovery" class="headerlink" title="DNN Operator Recovery"></a>DNN Operator Recovery</h3><p>Train a neural model to map assembly functions to DNN operators. Use representation learning and treat x86 opcodes as language tokens.</p>
<p><strong>Atomic OPs.</strong> Define atomic OPs over x86 opcodes. Each opcode is thus split into atomic OPs. Use atomic OP sequences represent a DNN operator.</p>
<p><strong>Dividing Opcodes into Atomic OPs.</strong> BPE. They split each opcode into a sequence of characters and counted consecutive characters to find the most frequent ones.</p>
<p><strong>Learning over Atomic OPs.</strong> Train a neural identifier model with a sequence of atomic OPs from an assembly function as inputs. The model outputs a 1D vector with N dimensions (N is the total number of unique DNN operators), where multiple “1” in the vector implies that this assembly function represents several fused DNN operators (融合算子). </p>
<p><strong>From Operators to Compilation Provenance.</strong> 直接使用之前的函数的embeddings分类，认为这个任务很简单</p>
<h3 id="DNN-Network-Topology-Recovery"><a href="#DNN-Network-Topology-Recovery" class="headerlink" title="DNN Network Topology Recovery"></a>DNN Network Topology Recovery</h3><p>A DNN operator has a fixed number of inputs and outputs. Use Intel Pin, a dynamic instrucmentation tool, to hook every callsite. Record the memory addresses of inputs/outputs passed to callsites and connect two operators if the successor’s inputs match the predecessor’s outputs.</p>
<p>This step does not rely on any compiler-specific assumptions, however, dynamic analysis is needed. (Intel Pin 也局限了使用的平台，其他架构或许没有这种工具或者无法监控内存，动态分析开销也比较大）</p>
<p>This dynamic analysis is not limited by “coverage”. （存在疑问，依赖于DNN编译器的先验知识）</p>
<h3 id="Dimension-and-Parameter-Recovery"><a href="#Dimension-and-Parameter-Recovery" class="headerlink" title="Dimension and Parameter Recovery"></a>Dimension and Parameter Recovery</h3><p>Inputs and parameters are typically stored separately in memory, whereas neighbor input/parameter elements are stored contiguously. （存在疑问，是栈空间还是堆空间，连续可能是偶然的）</p>
<p><strong>General Workflow.</strong> summarize operator invariant semantics with symbolic execution.</p>
<p>(1) log execution traces and use taint analysis to shroten the traces.</p>
<p>(2) use symbolic execution to summarize the input-output constraint of each assembly function.</p>
<p>(3) infer dimensions using patterns defined over constraints and futher extract parameters.</p>
<h4 id="Trace-Logging-and-Taint-Analysis"><a href="#Trace-Logging-and-Taint-Analysis" class="headerlink" title="Trace Logging and Taint Analysis"></a>Trace Logging and Taint Analysis</h4><p>Use Intel Pin to log the execution trace of an operator’s assembly function.</p>
	  
	</div>

	<!-- recommended posts -->
	

	<div>
  	<center>
	<div class="pagination">
<ul class="pagination">
	 
				
    	<li class="prev"><a href="/2022/10/27/Symbolic-Execution-Tech/" class="alignleft prev"><i class="fa fa-arrow-circle-o-left"></i>上一页</a></li>
  		

        <li><a href="/archives"><i class="fa fa-archive"></i>Archive</a></li>

		
		   <li class="next"><a href="/2022/10/21/NeurDP/" class="alignright next">下一页<i class="fa fa-arrow-circle-o-right"></i></a></li>         
        
	
</ul>
</div>

    </center>
	</div>

    <!-- share -->
    
        
    <div class="bdsharebuttonbox">
        <a href="#" class="bds_more" data-cmd="more"></a>
        <a href="#" class="bds_weixin" data-cmd="weixin" title="分享到微信"></a>
        <a href="#" class="bds_tsina" data-cmd="tsina" title="分享到新浪微博"></a>
        <a href="#" class="bds_fbook" data-cmd="fbook" title="分享到Facebook"></a>
        <a href="#" class="bds_twi" data-cmd="twi" title="分享到Twitter"></a>
        <a href="#" class="bds_linkedin" data-cmd="linkedin" title="分享到linkedin"></a>
        <a href="#" class="bds_evernotecn" data-cmd="evernotecn" title="分享到印象笔记"></a>
        <a href="#" class="bds_youdao" data-cmd="youdao" title="分享到有道云笔记"></a>
        <a href="#" class="bds_copy" data-cmd="copy" title="分享到复制网址"></a>
    </div>
    <script>
        window._bd_share_config={"common":{"bdSnsKey":{},"bdText":"","bdMini":"2","bdMiniList":false,"bdPic":"","bdStyle":"1","bdSize":"24"},"share":{}};
        with(document)0[(getElementsByTagName('head')[0]||body).appendChild(createElement('script')).src='http://bdimg.share.baidu.com/static/api/js/share.js?v=89860593.js?cdnversion='+~(-new Date()/36e5)];
    </script>


        

    
	
	<!-- comment -->
	
<section id="comment">
  <h2 class="title">留言</h2>
    	 
	 <div id="comment-thread"></div>
	 <div id="loading-spin"></div>
	 <script type="text/javascript">
	   getComments({
           type: "github" ? "github" : "github",       
	       user: "zijiancogito",
	       repo: "comment",
		   client_id: "b79cbe842579a612ed08",
           client_secret: "6585bb42b7c5b2fedf088cfce6b7e811f8803fe3",
		   no_comment: "暂时还没有留言呢，点击下面的按钮去留言吧！",
		   go_to_comment: "去留言",
		   no_issue: "no_issue",
		   issue_title: "Decompiling x86 Deep Neural Network Executables",
		   issue_id: "",
		   btn_class: "btn btn-primary",
		   comments_target: "#comment-thread",
		   loading_target: "#loading_spin"
		   });
	 </script>
  
</section>


	</div> <!-- col-md-9/col-md-12 -->
		
	
	<div id="side_meta">
		<div class="col-md-3" id="post_meta"> 

	<!-- date -->
	
	<div class="meta-widget">
	<i class="fa fa-clock-o"></i>
	2022-10-25 
	</div>
	

	<!-- categories -->
    
	<div class="meta-widget">
	<a data-toggle="collapse" data-target="#categorys"><i class="fa fa-folder"></i></a>	
    <ul id="categorys" class="tag_box list-unstyled collapse in">
          
  <li>
    <li><a href="/categories/编译/">编译<span>3</span></a></li>
  </li>

    </ul>
	</div>
	

	<!-- tags -->
	
	<div class="meta-widget">
	<a data-toggle="collapse" data-target="#tags"><i class="fa fa-tags"></i></a>		  
    <ul id="tags" class="tag_box list-unstyled collapse in">	  
	    
  <li><a href="/tags/Decompiler/">Decompiler<span>3</span></a></li> <li><a href="/tags/NN-Decompiler/">NN Decompiler<span>2</span></a></li>
    </ul>
	</div>
	

	<!-- toc -->
	<div class="meta-widget">
	
	   <a data-toggle="collapse" data-target="#toc"><i class="fa fa-bars"></i></a>
	   <div id="toc" class="toc collapse in">
			<ol class="toc-article"><li class="toc-article-item toc-article-level-1"><a class="toc-article-link" href="#Decompiling-x86-Deep-Neural-Network-Executables"><span class="toc-article-text">Decompiling x86 Deep Neural Network Executables</span></a><ol class="toc-article-child"><li class="toc-article-item toc-article-level-2"><a class="toc-article-link" href="#Abstract"><span class="toc-article-text">Abstract</span></a></li><li class="toc-article-item toc-article-level-2"><a class="toc-article-link" href="#Introduction"><span class="toc-article-text">Introduction</span></a></li><li class="toc-article-item toc-article-level-2"><a class="toc-article-link" href="#Preliminary"><span class="toc-article-text">Preliminary</span></a></li><li class="toc-article-item toc-article-level-2"><a class="toc-article-link" href="#Decompiling-DNN-Executables"><span class="toc-article-text">Decompiling DNN Executables</span></a></li><li class="toc-article-item toc-article-level-2"><a class="toc-article-link" href="#Design"><span class="toc-article-text">Design</span></a><ol class="toc-article-child"><li class="toc-article-item toc-article-level-4"><a class="toc-article-link" href="#Workflow"><span class="toc-article-text">Workflow</span></a></li></ol></li><li class="toc-article-item toc-article-level-3"><a class="toc-article-link" href="#DNN-Operator-Recovery"><span class="toc-article-text">DNN Operator Recovery</span></a></li><li class="toc-article-item toc-article-level-3"><a class="toc-article-link" href="#DNN-Network-Topology-Recovery"><span class="toc-article-text">DNN Network Topology Recovery</span></a></li><li class="toc-article-item toc-article-level-3"><a class="toc-article-link" href="#Dimension-and-Parameter-Recovery"><span class="toc-article-text">Dimension and Parameter Recovery</span></a><ol class="toc-article-child"><li class="toc-article-item toc-article-level-4"><a class="toc-article-link" href="#Trace-Logging-and-Taint-Analysis"><span class="toc-article-text">Trace Logging and Taint Analysis</span></a></li></ol></li></ol></li></ol></li></ol>
		</div>
	
	</div>
	
    <hr>
	
</div><!-- col-md-3 -->

	</div>
		

</div><!-- row -->



    </div>
  </div>
  <div class="container-narrow">
    <footer> <p>
  &copy; 2022 Zijian
  
      with help from <a href="http://hexo.io/" target="_blank">Hexo</a> and <a href="http://getbootstrap.com/" target="_blank">Twitter Bootstrap</a>. Theme by <a target="_blank" rel="noopener" href="http://github.com/wzpan/hexo-theme-freemind/">Freemind</a>.    
</p> </footer>
  </div> <!-- container-narrow -->
  


  
<a id="gotop" href="#">   
  <span>▲</span> 
</a>

<script src="/js/jquery.imagesloaded.min.js"></script>
<script src="/js/gallery.js"></script>
<script src="/js/bootstrap.min.js"></script>
<script src="/js/main.js"></script>
<script src="/js/search.js"></script> 


<link rel="stylesheet" href="/fancybox/jquery.fancybox.css" media="screen" type="text/css">
<script src="/fancybox/jquery.fancybox.pack.js"></script>
<script type="text/javascript">
(function($){
  $('.fancybox').fancybox();
})(jQuery);
</script>



   <script type="text/javascript">      
     var search_path = "search.xml";
	 if (search_path.length == 0) {
	 	search_path = "search.xml";
	 }
	 var path = "/" + search_path;
     searchFunc(path, 'local-search-input', 'local-search-result');
   </script>


<!-- syntax highlighting -->

  <script>
  marked.setOptions({
    highlight: function (code, lang) {
        return hljs.highlightAuto(code).value;
    }
  });
  function Highlighting(){
    var markdowns = document.getElementsByClassName('markdown');
    for(var i=0;i<markdowns.length;i++){
        if(markdowns[i].innerHTML) markdowns[i].innerHTML =marked(markdowns[i].innerHTML);
    }
  }
  window.addEventListener('DOMContentLoaded', Highlighting, false);
  window.addEventListener('load', Highlighting, false);
  </script>


<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [ ["$","$"], ["\\(","\\)"] ],
            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'],
            processEscapes: true
        }
    });
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax();
        for (var i = 0; i < all.length; ++i)
            all[i].SourceElement().parentNode.className += ' has-jax';
    });
</script>

<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML"></script>


</body>
</html>