<!DOCTYPE HTML>
<html>
<head>
  <meta charset="utf-8">
  
  <title>春秋一语</title>
  <meta name="author" content="Zijian">
  
  
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">

  
  <meta property="og:site_name" content="春秋一语"/>

  
    <meta property="og:image" content=""/>
  

  
  
    <link href="/favicon.png" rel="icon">
  

  <!-- CSS -->
  <link rel="stylesheet" href="/css/themes/journal.css" media="screen" type="text/css">
  <link rel="stylesheet" href="/css/font-awesome.css" media="screen" type="text/css">
  <link rel="stylesheet" href="/css/style.css" media="screen" type="text/css">
  <link rel="stylesheet" href="/css/responsive.css" media="screen" type="text/css">
  <link rel="stylesheet" href="/css/highlight.css" media="screen" type="text/css">
  <link rel="stylesheet" href="/css/highlight-default.min.css" media="screen" type="text/css">
  <link rel="stylesheet" href="/css/google-fonts.css" media="screen" type="text/css">
  <link rel="stylesheet" href="/css/comment.css" media="screen" type="text/css">
  <!--[if lt IE 9]>
    <script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script>
	<script src="https://cdnjs.cloudflare.com/ajax/libs/es5-shim/4.5.9/es5-shim.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/es5-shim/4.5.7/es5-sham.min.js"></script>
  <![endif]-->

  <script src="/js/jquery-2.0.3.min.js"></script>
  
    <script src="/js/marked.js"></script>
    <script src="/js/comment.js"></script>
    <script src="/js/timeago.min.js"></script>
    <script src="/js/highlight.min.js"></script>
	<script src="/js/spin.min.js"></script>
  
  <!-- analytics -->
  



<meta name="generator" content="Hexo 6.3.0"></head>

<body>
  <nav id="main-nav" class="navbar  navbar-default navbar-fixed-top" role="navigation">
    <div class="container">
      <button type="button" class="navbar-header navbar-toggle" data-toggle="collapse" data-target=".navbar-collapse">
	<span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
       <a class="navbar-brand" href="/">春秋一语</a>
      <div class="collapse navbar-collapse nav-menu">
		<ul class="nav navbar-nav">
		  
		  <li>
			<a href="/archives" title="All the articles.">
			  <i class="fa fa-archive"></i>Archives
			</a>
		  </li>
		  
		  <li>
			<a href="/categories" title="All the categories.">
			  <i class="fa fa-folder"></i>Categories
			</a>
		  </li>
		  
		  <li>
			<a href="/tags" title="All the tags.">
			  <i class="fa fa-tags"></i>Tags
			</a>
		  </li>
		  
		  <li>
			<a href="/about" title="About me.">
			  <i class="fa fa-user"></i>About
			</a>
		  </li>
		  
		</ul>
      </div>
    </div> <!-- container -->
</nav>
<div class="clearfix"></div>

  <div class="container">
    <div class="content">
      <div class="page-header ">
  <h1 class="title ">春秋一语</h1>
</div>

<div class="row page">

	
	<div class="col-md-9">
	

		<div class="slogan">
      <i class="fa fa-heart"></i>
      涉猎阅旧闻，暂使心魂澄
</div>    
		<div id="top_search"></div>
		<div class="mypage">
		
		<!-- title and entry -->
        <!-- render top articles firstly -->
        
		
            
		
            
		
            
		
            
		
            
			  
	
	<!-- display as entry -->	
		<h3 class="title-top">
			<div class="date"> 2022-10-20 </div>
			<div class="article-title"><a href="/2022/10/20/滕王阁序/"  class="article-title-text">滕王阁序</span></a><span class="badge">置顶</div>						
		</h3>
	


			  <div class="entry">
  <div class="row">
	
	
		
	
	</div>
  <a type="button" href="/2022/10/20/滕王阁序/#more" class="btn btn-default more">阅读此文</a>
</div>

            
		
            
		
        
        <!-- render other articles -->
        
           
			  
	
	<!-- display as entry -->	
		<h3 class="title">
			<div class="date"> 2022-11-04 </div>
			<div class="article-title"><a href="/2022/11/04/angr/" >angr</a></div>						
		</h3>
	


			  <div class="entry">
  <div class="row">
	
	
		<h1 id="Angr学习"><a href="#Angr学习" class="headerlink" title="Angr学习"></a>Angr学习</h1><h2 id="可能遇到的问题"><a href="#可能遇到的问题" class="headerlink" title="可能遇到的问题"></a>可能遇到的问题</h2><h3 id="Why-isn’t-symbolic-execution-doing-the-thing-I-want"><a href="#Why-isn’t-symbolic-execution-doing-the-thing-I-want" class="headerlink" title="Why isn’t symbolic execution doing the thing I want?"></a>Why isn’t symbolic execution doing the thing I want?</h3><ul>
<li><p>当遇到错误状态：<code>print(simgr)</code>, <code>print(simgr.errored)</code>.</p>
</li>
<li><p>如果遇到错误状态，并且不能立刻知道哪里错误，可以在crash点调用pdb shell，通过<code>simgr.errored[n].debug()</code>.</p>
</li>
<li><p>当状态没有达到期望的地址：<code>import pprint; pprint.pprint(state.history.descriptions.hardcopy)</code>. 会打印出符号执行引擎在每一步的高级总结和状态历史。可以看到基本块追踪和执行过的前驱。如果使用的是unicorn引擎，可以检查<code>state.history.bbl_addrs.hardcopy</code>来查看每一个unicorn的invocation里执行了哪些基本块。</p>
</li>
<li><p>当状态进入了错误的路径，检查什么约束让它走错了：<code>print(state.solver.constraints)</code>。 如果状态通过了一个分支，可以检查最近的分支通过<code>state.history.events[-1]</code>.</p>
</li>
</ul>
<h3 id="获取angr做了什么的诊断信息"><a href="#获取angr做了什么的诊断信息" class="headerlink" title="获取angr做了什么的诊断信息"></a>获取angr做了什么的诊断信息</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">import logging</span><br><span class="line">logging.getLogger(&#x27;angr&#x27;).setLevel(&#x27;DEBUG&#x27;)</span><br></pre></td></tr></table></figure>
<p><code>WARNING</code>级别是默认的，会输出一些信息，而<code>INFO</code>级别会输出更多信息，比如<code>logging.getLogger(&#39;angr.analyses&#39;).setLevel(&#39;INFO&#39;)</code>会输入所有的分析信息。</p>
<h3 id="序列化angr对象"><a href="#序列化angr对象" class="headerlink" title="序列化angr对象"></a>序列化angr对象</h3><p>使用Pickle。<code>pickle.dumps(obj, -1)</code></p>
<h3 id="angr的CFG和IDA为什么不同"><a href="#angr的CFG和IDA为什么不同" class="headerlink" title="angr的CFG和IDA为什么不同"></a>angr的CFG和IDA为什么不同</h3><p>IDA在函数调用处划分了基本块。使用<code>normalize=True</code>正则化基本块。</p>
<h2 id="Top-Level-Interfaces"><a href="#Top-Level-Interfaces" class="headerlink" title="Top Level Interfaces"></a>Top Level Interfaces</h2><p>首先需要将待分析的二进制加载到一个project中<br><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">import angr</span><br><span class="line">proj = angr.Project(&#x27;bin&#x27;)</span><br></pre></td></tr></table></figure><br>Project是angr的控制基础。可以用来分析或者模拟载入的二进制的执行。</p>
<p>将二进制代码映射到虚拟地址空间是复杂的。angr使用了CLE。CLE的结果叫做loader，通过<code>.loader</code>可以获取，现在用它可以看到共享库并可以在加载的地址空间执行基本的查询。</p>
<p>angr中有很多类，他们中的大多数都需要在project的基础上。</p>
<p>angr不推荐将project到处传递，而是使用<code>project.factory</code>，对于一般的常用对象都有便利的接口。</p>
<h4 id="Blocks"><a href="#Blocks" class="headerlink" title="Blocks"></a>Blocks</h4><p>接口有project.factory.block()，可以从给定地址提取一个基本块。angr以基本块为单位分析代码。会返回一个Block对象，包含很多有趣的信息。<br><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">block =  proj.factory.block(proj.entry)</span><br></pre></td></tr></table></figure></p>
<h4 id="States"><a href="#States" class="headerlink" title="States"></a>States</h4><p>Project对象只是程序的初始镜像。当开始模拟执行时，会用到一个特殊的对象simulated program state <code>SimState</code>.<br><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">state = proj.factory.entry_state()</span><br></pre></td></tr></table></figure><br>SimState包含了程序的内存，寄存器，文件系统数据，等各种会在执行过程中发生变化的“live data”。使用<code>state.regs</code>和<code>state.mem</code>可以访问当前状态的寄存器和内存。<br><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">state.regs.rip</span><br><span class="line">state.regs.rax</span><br><span class="line">state.mem[proj.entry].int.resolved</span><br></pre></td></tr></table></figure><br>这些不是Python的int变量，而是位向量<em>bitvectors</em>。Python的整形和CPU中的数据没有相同的语义，因此使用位向量来表示CPU中的数据。每一个位向量都有一个<code>.length</code>属性来描述比特的宽度。</p>
<p>转换Python整数到位向量的方法<br><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">bv = state.solver.BVV(0x1234, 32)  # create a 32-bit-wide bitvector with value 0x1234</span><br><span class="line">state.solver.eval(bv)  # convert to Python int</span><br></pre></td></tr></table></figure><br>位向量可以存回寄存器和内存中，或者直接将一个python整数存储，它会被转换搭配合适大小的位向量<br><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">state.regs.rsi = state.solver.BVV(3, 64)</span><br><span class="line">state.mem[0x1000].long = 4  # directly store python ints to memory</span><br></pre></td></tr></table></figure></p>
<p><code>mem</code>接口可能有点困惑，因为它使用了一些非常多的python magic。简短地介绍一下它怎么用：</p>
<ul>
<li>使用array[index]来指定一个地址</li>
<li>使用<code>.&lt;type&gt;</code>来指定这个内存必须用<type>类型解释，比如char，short等</li>
<li>存一个value进去，不管是一个bitvector还是一个python int</li>
<li>使用<code>.resolved</code> to get the value as a bitvector</li>
<li>Use <code>.concrete</code>to get the value as a Python int</li>
</ul>
<p>如果在读取寄存器时遇到了非常奇怪的值，比如<code>&lt;BV64 reg_48_11_64&#123;UNINITIALIZED&#125;&gt;</code>,这依然是一个64位的位向量，但是不包含具体的数值。但是它有一个名字！叫做<strong>符号</strong>。是符号执行时需要用到的。</p>
<h4 id="Simulation-Managers"><a href="#Simulation-Managers" class="headerlink" title="Simulation Managers"></a>Simulation Managers</h4><p>如果状态能够让我们用来表示一个给定时间点的程序，那么就一定能够获取到下一个时间点的程序。模拟管理器就是angr进行执行，模拟的一个接口。简短介绍一下，如何将先前创建的状态向前tick几个基本块。</p>
<p>首先，创建了一个模拟管理器。构造器需要输入一个状态或者一个状态列表</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">simgr = proj.factory.simulation_manager(state)</span><br><span class="line">simgr.active</span><br></pre></td></tr></table></figure>
<p>模拟管理器可能包含数个状态的存储空间（stashes）。默认的stash，<code>active</code>，是使用我们传进去的状态初始化的。可以通过<code>simgr.active[0]</code>来查看更多的状态。</p>
<p>现在。。。准备，开始进行执行<br><code>simgr.step()</code></p>
<p>执行了一个基本块之后，可以再次查看一下active stash，现在它已经被更新，但是不会改变我们的初始状态。SimState对象在执行对称中是不可修改的。可以安全的使用一个状态作为多轮执行的“base”</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; simgr.active</span><br><span class="line">[&lt;SimState @ 0x1020300&gt;]</span><br><span class="line">&gt;&gt;&gt; simgr.active[0].regs.rip	# new and exciting!</span><br><span class="line">&lt;BV64 0x1020300&gt;</span><br><span class="line">&gt;&gt;&gt; state.regs.rip	# still the same!</span><br><span class="line">&lt;BV64 0x401670&gt;</span><br></pre></td></tr></table></figure>
<h4 id="Analyses"><a href="#Analyses" class="headerlink" title="Analyses"></a>Analyses</h4><p>angr有一些内置的分析，可以用来从程序中提取一些有趣的信息。如果想要知道每一个怎么使用需要看API文档。<br>简单的快速获取控制流图的例子：<br><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">proj = angr.Project(&#x27;test&#x27;, auto_load_libs=False)</span><br><span class="line">cfg = proj.analyses.CFGFast()</span><br><span class="line">cfg.graph</span><br><span class="line">len(cfg.graph.nodes())</span><br><span class="line">entry_node = cfg.get_any_node(proj.entry)</span><br><span class="line">len(list(cfg.graph.successors(entry_node)))</span><br></pre></td></tr></table></figure></p>
<h2 id="Loading-a-Binary"><a href="#Loading-a-Binary" class="headerlink" title="Loading a Binary"></a>Loading a Binary</h2><p>CLE Loads Everything！</p>
<h4 id="Loaded-Objects"><a href="#Loaded-Objects" class="headerlink" title="Loaded Objects"></a>Loaded Objects</h4><p>CLE加载器 <code>cle.loader</code> 代表加载的二进制对象，加载和映射的内存空间的集合体。每一个二进制对象被对应文件类型的加载器后端加载。比如<code>cle.ELF</code>。</p>
<p>内存中也有一些对象是没有对应任何加载的二进制的。例如，用来提供本地现成存储支持的对象。和用来提供未解决的符号的外部对象。</p>
<p>通过<code>loader.all_objects</code>可以获取到CLE加载的所有对象以及更多目标类型。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">proj.loader.all_objects</span><br><span class="line">proj.loader.main_object</span><br><span class="line">proj.loader.shared_objects</span><br><span class="line">proj.loader.all_elf_objects</span><br><span class="line">proj.loader.extern_object</span><br><span class="line">proj.loader.kernel_object</span><br><span class="line">proj.loader.find_object_containing(0x400000) # get a reference to an object gitven **an address *in* it**</span><br></pre></td></tr></table></figure>
<p>可以直接和对象交互来获取其中的metadata</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">obj = proj.loader.main_object</span><br><span class="line">obj.entry</span><br><span class="line">obj.min_addr, obj.max_addr</span><br></pre></td></tr></table></figure>
<h4 id="Symbols-and-Relocations"><a href="#Symbols-and-Relocations" class="headerlink" title="Symbols and Relocations"></a>Symbols and Relocations</h4><p>符号是一个地址对应的名字。最简单的使用CLE获取符号的方式是<code>loader.find_symbol</code>。它可以输入一个名字或者一个地址，然后返回一个Symbol对象。</p>
<p>符号最有用的属性是它的<strong>名字，所有者，地址</strong>。但是地址可能是有歧义的。符号对象有三种方式来记录他的地址：</p>
<ul>
<li><code>.rebased_addr</code> 是它在全局地址空间中的地址</li>
<li><code>.linked_addr</code> 是他对于二进制prelinked的基地址的相对地址<br>_ <code>.relative_addr</code> 是相对于整个object的基址的相对地址。</li>
</ul>
<p>除了提供调试信息之外，符号也可以用来支持动态链接。libc提供了strcmp symbol，很多二进制都依赖它。如果询问CLE，获取strcmp符号，他将会返回它是<em>import symbol</em>。它没有实际的地址，但是会提供一个指向符号的reference从而解析它 <code>.resolvedby</code><br><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">strcmp.is_export</span><br><span class="line">strcmp.is_import</span><br><span class="line">&gt;&gt;&gt; strcmp.resolvedby</span><br><span class="line">&lt;Symbol &quot;strcmp&quot; in libc.so.6 at 0x1089cd0&gt;</span><br></pre></td></tr></table></figure></p>
<p>imports和exports的link是由<em>relocations</em>处理的。relocation指当你把[import]和export的symbol匹配时，需要将export的地址写到[location]中，格式是[format]。使用<code>obj.relocs</code>可以看到一个对象(<code>Relocation</code>)的完整列表。使用<code>obj.imports</code>可以将符号名字映射到Relocation上。而对于export symbol没有对应的列表。</p>
<p>重定位对应的import symbol可以通过<code>.symbol</code>访问。relocation的地址将会写入到访问中，通过Symbol的任何地址标识，你可以通过访问<code>.owner</code>来获取到对象的引用。</p>
<p>如果import不能被解析成任何export，可能是因为共享库找不到，CLE将会自动更新外部对象<code>loader.extern_obj</code>来声明，它提供了符号作为export。</p>
<h3 id="Loading-Options"><a href="#Loading-Options" class="headerlink" title="Loading Options"></a>Loading Options</h3><p>如果在使用<code>angr.Project</code>加载东西时，想要向<code>cle.Loader</code>中传递一个选项，只需要直接向Project的构造器中传递关键词，然后它就会传递到CLE中，可以看CLE的API文档。</p>
<p>基本的选项有auto_load_libs, froce_load_libs, except_missing_libs, skip_libs.</p>
<h4 id="Pre-Binary-Options"><a href="#Pre-Binary-Options" class="headerlink" title="Pre-Binary Options"></a>Pre-Binary Options</h4><p>如果想要针对特定的二进制对象给特定的选项，CLE也可以实现。参数main_opts和lib_opts可以实现。<code>main_opts</code>是从选项名称到选项值的映射，<code>lib_opts</code>是从库名称到字典（选项名称-&gt;选项值）的映射。</p>
<ul>
<li>backend：使用的后端是哪种，class还是name</li>
<li>base_addr：基址</li>
<li>entry_point：入口点</li>
<li>arch：架构</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; angr.Project(&#x27;examples/fauxware/fauxware&#x27;, main_opts=&#123;&#x27;backend&#x27;: &#x27;blob&#x27;, &#x27;arch&#x27;: &#x27;i386&#x27;&#125;, lib_opts=&#123;&#x27;libc.so.6&#x27;: &#123;&#x27;backend&#x27;: &#x27;elf&#x27;&#125;&#125;)</span><br><span class="line">&lt;Project examples/fauxware/fauxware&gt;</span><br></pre></td></tr></table></figure>
<h4 id="Symbolic-Function-Summaries"><a href="#Symbolic-Function-Summaries" class="headerlink" title="Symbolic Function Summaries"></a>Symbolic Function Summaries</h4><p>Project试图使用符号总结symbolic summaries（SimProcedures）来代理对库函数的调用。这些内置的过程可以通过<code>angr.SIM_PROCEDURES</code>获取</p>
<h4 id="Hooking"><a href="#Hooking" class="headerlink" title="Hooking"></a>Hooking</h4><p>angr使用python summary替代一个库代码的方法叫hooking。在模拟的过程中，每一步，angr都检查当前的地址是否被hook，如果是，就运行hook而不是运行那个地址的二进制代码。Hook的方法是使用API <code>proj.hook(addr, hook)</code>，其中hook是一个SimProcedure。可以使用<code>.is_hooked</code>和<code>.unhook</code>,<code>.hooked_by</code>管理项目中的钩子。</p>
<p>使用API hook一个地址的替代方法是，使用自己的off-the-cuff函数，通过使用proj.hook(addr)作为函数修饰。如果这么做了，可以选择制定一个length<br>关键字来使得执行跳转一定的字节，在hook完成之后。</p>
<p>另外，还可以使用<code>proj.hook_symbol(name, hook)</code>，提供符号的名字来hook符号所活跃的地址。</p>
<h2 id="Solver-Engine"><a href="#Solver-Engine" class="headerlink" title="Solver Engine"></a>Solver Engine</h2><p>angr的强大之处不仅在于模拟器，而是可以进行符号执行。使用符号表示一个变量，并且在对应变量上执行算术操作会生成一个操作的树（叫AST）。AST可以被翻译称SMT求解器的约束，例如Z3，为了回答问题：给定这个操作序列的输出，输入应该是什么样的。</p>
<h3 id="Working-with-Bitvectors"><a href="#Working-with-Bitvectors" class="headerlink" title="Working with Bitvectors"></a>Working with Bitvectors</h3><p>位向量是一个比特序列。可以有任意的比特序列，称之为位向量，并且在他们之上做数学操作。</p>
<p>对不同长度的位向量进行操作会触发类型错误。但是可以对位向量进行extend到合适的长度。<br><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">weird_nine = state.solver.BVV(9,27)</span><br><span class="line">weird_nine.zero_extend(64, 27)</span><br></pre></td></tr></table></figure></p>
<p><code>zero_extend</code>会在位向量左侧添加给定数量的0。<code>sign_extend</code>会使用最高位的比特重复。</p>
<p>创建符号变量<br><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">x = state.solve.BVS(&quot;x&quot;, 64)</span><br><span class="line">y = state.solve.BVS(&quot;y&quot;, 64)</span><br></pre></td></tr></table></figure></p>
<p>x和y现在是符号变量。你提供的名字后面都会自动被附加后缀计数器。你可以随便对他们做算术运算，但是不会得到一个值，而是会得到一个AST。<br><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; x + one</span><br><span class="line">&lt;BV64 x_9_64 + 0x1&gt;</span><br><span class="line">&gt;&gt;&gt; x - y</span><br><span class="line">&lt;BV64 x_9_64 - y_10_64&gt;</span><br></pre></td></tr></table></figure><br>x,y和one也都是AST，任何位向量都是一个操作树，即使这个树的深度只有1。为了理解这一点，我们来学习一下如何处理AST。</p>
<p>每个AST都有一个<code>.op</code>和<code>.args</code>。op是一个字符串，代表执行的操作，args是该操作需要输入的值。除非操作是BVV或BVS等少数，参数全部是其他AST，树的终止节点是BVV或者BVS。<br><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; tree = (x + 1) / (y + 2)</span><br><span class="line">&gt;&gt;&gt; tree</span><br><span class="line">&lt;BV64 (x_9_64 + 0x1) / (y_10_64 + 0x2)&gt;</span><br><span class="line">&gt;&gt;&gt; tree.op</span><br><span class="line">&#x27;___floordiv__&#x27;</span><br><span class="line">&gt;&gt;&gt; tree.args</span><br><span class="line">(&lt;BV64 x_9_64 + 0x1&gt;, &lt;BV64 y_10_64 + 0x2&gt;)</span><br><span class="line">&gt;&gt;&gt; tree.args[0].op</span><br><span class="line">&#x27;__add__&#x27;</span><br><span class="line">&gt;&gt;&gt; tree.args[0].args</span><br><span class="line">(&lt;BV64 x_9_64&gt;, &lt;BV64 0x1&gt;)</span><br><span class="line">&gt;&gt;&gt; tree.args[0].args[1].op</span><br><span class="line">&#x27;BVV&#x27;</span><br><span class="line">&gt;&gt;&gt; tree.args[0].args[1].args</span><br><span class="line">(1, 64)</span><br></pre></td></tr></table></figure></p>
<p>之后的介绍中，我们会使用“bitvector”来代表任何最顶层操作会产生位向量的AST。也有一些其他数据类型用AST表示，包括浮点数和布尔值。</p>
<h3 id="Symbolic-Constraints"><a href="#Symbolic-Constraints" class="headerlink" title="Symbolic Constraints"></a>Symbolic Constraints</h3><p>对任何两个相似类型的AST进行的比较操作会生成另一个AST，不是bitvector而是布尔符号<br><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; x == 1</span><br><span class="line">&lt;Bool x_9_64 == 0x1&gt;</span><br><span class="line">&gt;&gt;&gt; one_hunderd &gt; 5</span><br><span class="line">&lt;Bool True&gt;</span><br></pre></td></tr></table></figure></p>
<p>在使用angr的时候不应该直接比较两个变量，在if或者while语句中，因为结果可能不会有一个具体的真值。即使有真值<code>if one &gt; one_hundred</code>也会引发异常。相反，应该使用<code>solve.is_true</code>和<code>solver.is_false</code>，来test具体的真假而不使用进行约束求解。</p>
<h3 id="约束求解"><a href="#约束求解" class="headerlink" title="约束求解"></a>约束求解</h3><p>可以将一个符号布尔看作一个符号变量的合法值的断言通过将它作为约束加到状态上。然后可以通过查询符号表达式的evaluation来获取符号变量的合法值。<br><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; state.solver.add(x &gt; y)</span><br><span class="line">&gt;&gt;&gt; state.solver.add(y &gt; 2)</span><br><span class="line">&gt;&gt;&gt; state.solver.add(10 &gt; x)</span><br><span class="line">&gt;&gt;&gt; state.solver.eval(x)</span><br><span class="line">4</span><br></pre></td></tr></table></figure></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; state = proj.factory.entry_state()</span><br><span class="line">&gt;&gt;&gt; input = state.solver.BVS(&#x27;input&#x27;, 64)</span><br><span class="line">&gt;&gt;&gt; operation = (((input + 4) * 3) &gt;&gt; 1) + input</span><br><span class="line">&gt;&gt;&gt; output = 200</span><br><span class="line">&gt;&gt;&gt; state.solver.add(operation == output)</span><br><span class="line">&gt;&gt;&gt; state.solver.eval(input)</span><br><span class="line">0x3333333333...</span><br></pre></td></tr></table></figure>
<p>可以通过<code>state.satisfiable()</code>来判断一个状态的可满足性。<br><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; state.solver.add(input &lt; 2**32)</span><br><span class="line">&gt;&gt;&gt; state.satifisable()</span><br><span class="line">False</span><br></pre></td></tr></table></figure></p>
<p>可以evaluate更复杂的表达式<br><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; state = proj.factory.entry_state()</span><br><span class="line">&gt;&gt;&gt; state.solver.add(x - y &gt;= 4)</span><br><span class="line">&gt;&gt;&gt; state.solver.add(y &gt; 0)</span><br><span class="line">&gt;&gt;&gt; state.solver.eval(x)</span><br><span class="line">5</span><br><span class="line">&gt;&gt;&gt; state.solver.eval(y)</span><br><span class="line">1</span><br><span class="line">&gt;&gt;&gt; state.solver.eval(x + y)</span><br><span class="line">6</span><br></pre></td></tr></table></figure></p>
<p>可以看到eval是一个常用的将bitvector转换成python primitive的方法，同时保留了状态的完整性。这就是我们使用eval将具体的位向量转换成python int的方法。</p>
<p>x和y可以被用在新状态中，尽管它已经被用在旧的状态中，变量不被绑定在任何状态中，是自由存在的！</p>
<h3 id="Floating-point-numbers"><a href="#Floating-point-numbers" class="headerlink" title="Floating point numbers"></a>Floating point numbers</h3><p>除了宽度之外，浮点数还有一个sort。可以使用FPV和FPS创建浮点符号。<br><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; state = proj.factory.entry_state()</span><br><span class="line">&gt;&gt;&gt; a = state.solver.FPV(3.2, state.solver.fp.FSORT_DOUBLE)</span><br><span class="line">&gt;&gt;&gt; a</span><br><span class="line">&lt;FP64 FPV(3.2, DOUBLE)&gt;</span><br><span class="line">&gt;&gt;&gt; a + b</span><br><span class="line">&lt;FP64 fpAdd(&#x27;RNE&#x27;, FPV(3.2, DOUBLE), FPS(&#x27;FP_b_0_64&#x27;, DOUBLE))&gt;</span><br><span class="line">&gt;&gt;&gt; a + 4.4</span><br><span class="line">&lt;FP64 FPV(7.6000000000000005, DOUBLE)&gt;</span><br><span class="line">&gt;&gt;&gt; b + 2 &lt; 0</span><br><span class="line">&lt;Bool fpLT(fpAdd(&#x27;RNE&#x27;, FPS(&#x27;FP_b_0_64&#x27;, DOUBLE), FPV(2.0, DOUBLE)), FPV(0.0, DOUBLE))&gt;</span><br></pre></td></tr></table></figure></p>
<h3 id="More-Solving-Methods"><a href="#More-Solving-Methods" class="headerlink" title="More Solving Methods"></a>More Solving Methods</h3><p>eval可以给表达式一个可能的解，但是如果需要更多的解？<br>更多求解方式如下</p>
<ul>
<li>solver.eval(expression)会给出表达式一个可能的解</li>
<li>solver.eval_one(expression)会给出表达式的解，并且如果有超过一个解会抛出错误</li>
<li>solver.eval_upto(expression, n)会给出表达式的n个解，如果解的总数小于n会给出小于n个解</li>
<li>solver.eval_atleast(expression, n)会给出给定表达式的n个解，如果可能的解的个数小于n会抛出错误</li>
<li>solver.eval_exact(expression, n)会给出表达式的n个解，如果可能的解大于或者小于n会抛出错误</li>
<li>solver.min(expression)会给出表达式最小可能的解</li>
<li>solver.max(expression)会给出表达式最大可能的解</li>
</ul>
<p>除此之外，所有这些方法都可以传入这些参数：</p>
<ul>
<li>extra_constraints可以传入一组约束，这些约束在eval的过程中会被考虑到，但是不会加入状态中</li>
<li>cast_to可以传入一个数据类型，将结果进行强制转换。目前，只支持int和byts。例如，<code>state.solver.eval(state.solver.BVV(0x41424344, 32), cast_to=bytes)</code>将会返回会<code>b&#39;ABCD&#39;</code>。</li>
</ul>
<h2 id="Program-State"><a href="#Program-State" class="headerlink" title="Program State"></a>Program State</h2><p>任何的bitvector类型的AST都可以被存储在寄存器或者内存中。<br><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; state.regs.rbp = state.regs.rsp</span><br><span class="line">&gt;&gt;&gt; state.mem[0x1000].uint64_t = state.regs.rdx</span><br><span class="line">&gt;&gt;&gt; state.regs.rbp = state.mem[state.regs.rbp].uint64_t.resolved</span><br><span class="line">&gt;&gt;&gt; state.regs.rax += state.mem[state.regs.rsp + 8].uint64_t.resolved</span><br></pre></td></tr></table></figure></p>
<h3 id="Basic-Execution"><a href="#Basic-Execution" class="headerlink" title="Basic Execution"></a>Basic Execution</h3><p>符号执行是怎么工作的: state.step()。<br>这个方法会执行一部的符号执行，并返回SimSuccessors对象。符号执行可以产生多个继承状态。目前，只关注对象的<code>.successors</code>属性，他是一个给定步数的包含所有后继的列表。</p>
<p>angr符号执行的过程是获取程序中的指令的操作，然后根据它改变SimState。当到达<code>if (x &gt; 4)</code>这样的语句时，会执行x&gt;4，结果是<Bool x_32_1 > 4&gt;.</p>
<p>angr保留true和false两个分支。会产生两个独立的后继状态。如果是true，就将x&gt;4加入到约束中，反之，将!(x&gt;4)加入到约束中。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">&gt;&gt;&gt; proj = angr.Project(&#x27;examples/fauxware/fauxware&#x27;)</span><br><span class="line">&gt;&gt;&gt; state = proj.factory.entry_state(stdin=angr.SimFile)  # ignore that argument for now - we&#x27;re disabling a more complicated default setup for the sake of education</span><br><span class="line">&gt;&gt;&gt; while True:</span><br><span class="line">...     succ = state.step()</span><br><span class="line">...     if len(succ.successors) == 2:</span><br><span class="line">...         break</span><br><span class="line">...     state = succ.successors[0]</span><br><span class="line">​</span><br><span class="line">&gt;&gt;&gt; state1, state2 = succ.successors</span><br><span class="line">&gt;&gt;&gt; state1</span><br><span class="line">&lt;SimState @ 0x400629&gt;</span><br><span class="line">&gt;&gt;&gt; state2</span><br><span class="line">&lt;SimState @ 0x400699&gt;</span><br></pre></td></tr></table></figure>
<p>使用<code>state.posix.stdin.load(0, state.posix.stdin.size)</code>来获取从stdin读入的bitvector。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; input_data = state1.posix.stdin.load(0, state1.posix.stdin.size)</span><br><span class="line"></span><br><span class="line">&gt;&gt;&gt; state1.solver.eval(input_data, cast_to=bytes)</span><br><span class="line">b&#x27;\x00\x00\x00\x00\x00\x00\x00\x00\x00SOSNEAKY\x00\x00\x00&#x27;</span><br><span class="line"></span><br><span class="line">&gt;&gt;&gt; state2.solver.eval(input_data, cast_to=bytes)</span><br><span class="line">b&#x27;\x00\x00\x00\x00\x00\x00\x00\x00\x00S\x00\x80N\x00\x00 \x00\x00\x00\x00&#x27;</span><br></pre></td></tr></table></figure>
<p>为了执行到state1路径，需要给定字符串SOSNEAKY。为了执行到state2路径，需要给其他字符串。</p>
<h3 id="State-Presets"><a href="#State-Presets" class="headerlink" title="State Presets"></a>State Presets</h3><p>创建状态的方式：</p>
<ul>
<li><code>.blank_state()</code>构建了一个空白状态，访问他时会返回一个没有约束的符号值</li>
<li><code>.entry_state()</code>构建了一个main二进制的入口点状态</li>
<li><code>.full_init_state()</code>构建了一个在入口点之前需要执行的状态，例如共享库构造或者初始化。完成之后将跳转到入口点。</li>
<li><strong><code>.call_state()</code>构造一个执行给定函数的状态。</strong></li>
</ul>
<p>可以通过下面这些参数定制状态：</p>
<ul>
<li>addr可以指定开始的地址</li>
<li>如果需要传递命令行参数或环境，可以通过args参数和通过env传递环境变量的目录到entry_state和full_init_state。这些结构中的值可以是字符串或者位向量，并且会作为参数和环境序列化为状态传递到模拟执行中。默认的args是空列表。</li>
<li>如果想要argc变成符号，需要传入一个符号位向量argc到entry_state和full_init_state中。如果加了这个符号，就需要加一个约束，保证argv的个数不超过argc</li>
<li>使用call state时，用<code>.call_state(addr, arg1, arg2, ...)</code>，其中addr是想要调用的函数的地址，argN是那个函数的第n个参数，可以是python integer，string或 array， bitvector。如果想要分配内存，传递一个对象的指针进去，需要用PointerWrapper打包，例如<code>angr.PointerWrapper(&quot;point to me!&quot;)</code>。这个api的结果可能是不可预测的。</li>
<li>为了通过call_state指定调用约定，可以传递一个SimCC实例作为cc参数。</li>
</ul>
<p>更多的构造器和选项需要看project.factory object (an AngrObjectFactory)文档</p>
<h3 id="Low-level-interface-for-memory"><a href="#Low-level-interface-for-memory" class="headerlink" title="Low level interface for memory"></a>Low level interface for memory</h3><p>state.mem接口可以很方便地从内存中加载特定类型的数据，但是如过想要加载或者存储原始数据，从一个给定的内存范围，是处理不了的。使用state.memory的.load(addr, size)和.store(addr, val)方法<br><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">&gt;&gt;&gt; s = proj.factory.blank_state()</span><br><span class="line">&gt;&gt;&gt; s.memory.store(0x4000, s.solver.BVV(0x0123456789abcdef0123456789abcdef, 128))</span><br><span class="line">&gt;&gt;&gt; s.memory.load(0x4004, 6) # load-size is in bytes</span><br><span class="line">&lt;BV48 0x89abcdef0123&gt;</span><br></pre></td></tr></table></figure><br>可以看到数据是以大端序的风格存储的。如果想要交换字节，可以用关键字endness。endness必须是Endness枚举类型的成员在archinfo包中。待分析程序的endness可以通过arch.memory_endness获取，例如state.arch.memory_endness<br><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; import archinfo</span><br><span class="line">&gt;&gt;&gt; s.memory.load(0x4000, 4, endness=archinfo.Endness.LE)</span><br><span class="line">&lt;BV32 0x67452301&gt;</span><br></pre></td></tr></table></figure><br>还有寄存器访问的低级接口state.registers。他使用和state.memory相同的API。</p>
<h3 id="State-Options"><a href="#State-Options" class="headerlink" title="State Options"></a>State Options</h3><p>对每一个SimState对象，都有一个他所有可能的选项state.options集合。每个选项控制着执行引擎的行为。可以通过angr.options获取所有可以加入到状态中的合法选项。合法选项都以大写字母命名，还有一些常用的将对象绑定在一起的选项用小写字母命名。</p>
<p>当使用构造器创建一个SimState时，可以传递关键参数add_options和remove_options来改变默认的初始参数集合<br><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"># Example: enable lazy solves, an option that causes state satisfiability to be checked as infrequently as possible.</span><br><span class="line"># This change to the settings will be propagated to all successor states created from this state after this line.</span><br><span class="line">&gt;&gt;&gt; s.options.add(angr.options.LAZY_SOLVES)</span><br><span class="line"></span><br><span class="line"># Create a new state with lazy solves enabled</span><br><span class="line">&gt;&gt;&gt; s = proj.factory.entry_state(add_options=&#123;angr.options.LAZY_SOLVES&#125;)</span><br><span class="line"></span><br><span class="line"># Create a new state without simplification options enabled</span><br><span class="line">&gt;&gt;&gt; s = proj.factory.entry_state(remove_options=angr.options.simplification)</span><br></pre></td></tr></table></figure></p>
<h3 id="State-Plugins"><a href="#State-Plugins" class="headerlink" title="State Plugins"></a>State Plugins</h3><p>存储在SimState中的内容都是以plugin的形式附加在状态中的。几乎状态中的所有属性都是plugin，包括memory, registers，mem，regs，solver等。这种设计使得实现新的数据存储很容易。</p>
<h4 id="The-globals-plugin"><a href="#The-globals-plugin" class="headerlink" title="The globals plugin"></a>The globals plugin</h4><p>state.globals是一个非常简单的插件，他实现了标准的python字典，可以在状态中随意存储数据</p>
<h4 id="The-history-plugin"><a href="#The-history-plugin" class="headerlink" title="The history plugin"></a>The history plugin</h4><p>state.history是很重要的插件，存储了一个状态在执行中经历的路径上的历史数据。是一个包含多个历史节点的链表，每一个都表示了一轮执行，可以通过<code>state.history.parent.parent</code>对他进行遍历。</p>
<p>为了更方便的使用这个结构，history还提供了一些遍历特定值的方式。这些值存储为<code>history.recent_NAME</code>，迭代器是history.NAME。例如，</p>
<ul>
<li><code>for addr in state.history.bbl_addrs: print hex(addr)</code>会输出基本块地址trace，</li>
<li>而state.history.recent_bbl_addrs是最近几步执行的基本块列表</li>
<li>state.history.parent.recent_bbl_addrs前一步执行的基本块的列表</li>
<li>.hardcopy可以快速获取这些值的列表，例如state.history.bbl_addrs.hardcopy。</li>
</ul>
<p>总之，迭代器可以实现基于检索的访问</p>
<p>下面列出一些历史中存储的值</p>
<ul>
<li>history.descriptions是一个字符串列表，描述了状态的每一轮执行</li>
<li>history.bbl_addrs是一个状态执行的基本块地址列表。每一轮的执行中可能有多个，并不是所有的地址都在二进制中对应，有一些地址可能是SimProcedures hook的地方。</li>
<li>history.jumpkinds是状态历史中每一个控制转移的方向，是VEX 枚举字符串类型</li>
<li>history.jump_guards 是描述状态遇到的所有分支的conditions</li>
<li>history.events是执行过程中发生的“有趣事件”的语义列表，比如，符号跳转条件，程序弹出了一个提示窗口，程序执行终止并返回一个exit code。</li>
<li>history.actions通常是空的，除非你在状态中加入了angr.options.refs，它用来记录所有的内存，寄存器，临时值</li>
</ul>
<h4 id="The-callstack-plugin"><a href="#The-callstack-plugin" class="headerlink" title="The callstack plugin"></a>The callstack plugin</h4><p>angr会追踪模拟过程中的调用栈。调用栈也是一个节点的链表，但是不提供迭代器。可以直接通过state.callstack迭代来获取每一个活跃的栈帧，以从新到旧的顺序。如果只想要栈顶的，那就是state.callstack</p>
<ul>
<li>callstack.func_addr是正在执行的函数的地址</li>
<li>callstack.call_site_addr是调用当前函数的基本块的地址</li>
<li>callstack.stack_ptr是从当前函数的开头的站指针的值</li>
<li>callstack.ret_addr是当前函数所返回到的地址。</li>
</ul>
<h3 id="More-about-I-O-Files-file-systems-and-network-sockets"><a href="#More-about-I-O-Files-file-systems-and-network-sockets" class="headerlink" title="More about I/O: Files, file systems, and network sockets"></a>More about I/O: Files, file systems, and network sockets</h3><p>看Working with File System，Sockets， and Pipes章节</p>
<h2 id="Simulation-Managers-1"><a href="#Simulation-Managers-1" class="headerlink" title="Simulation Managers"></a>Simulation Managers</h2><p>angr中最重要的控制接口是模拟管理器，</p>
<h3 id="Stepping"><a href="#Stepping" class="headerlink" title="Stepping"></a>Stepping</h3><p>模拟管理器最基本的能力就是将所有的状态向前推进一个基本块，在给定的stash中。使用.step()</p>
<p>.step()和.run()</p>
<h3 id="Stash-Management"><a href="#Stash-Management" class="headerlink" title="Stash Management"></a>Stash Management</h3><p>理解：stash就是一个列表，存放一些具有相同特征的状态，比如用一些filter过滤出来的，接下来要执行的等。</p>
<p>stash之间转换状态使用.move()，参数是from_stash, to_stash, filter_func（可选的，默认的是move所有）</p>
<p>每个stash是一个列表，可以索引或者迭代访问列表中的每一个合法状态。还有一些其他方式访问，比如如果使用stash的名字，前缀加one_，可以获取到stash的第一个状态，如果前缀加mp_，可以获取mulpyplexed版本的stash</p>
<h3 id="Stash-types"><a href="#Stash-types" class="headerlink" title="Stash types"></a>Stash types</h3><ul>
<li>active: 这个stash包含了默认要step大片的状态，除非指定了其他的stash</li>
<li>deadended：会进入到deadended stash的状态，当程序由于某些原因不能继续执行，比如没有合法的指令，不合法的指令指针，所有后继都不能满足</li>
<li>pruned：当使用LAZY_SOLVES，</li>
<li>unconstrained</li>
<li>unsat</li>
</ul>
<h3 id="Simple-Exploration"><a href="#Simple-Exploration" class="headerlink" title="Simple Exploration"></a>Simple Exploration</h3><p>找到到达特定地址的状态，使用.explore()方法。使用参数find,执行将会运行直到找到和find匹配的条件。结果会在found stash中<br>也可以指定一个avoid条件，结果会存在avoided stash中<br>num_find参数控制着的个数，默认是1</p>
<h3 id="Exploration-Techniques"><a href="#Exploration-Techniques" class="headerlink" title="Exploration Techniques"></a>Exploration Techniques</h3><p>使用探索技术调用simgr.use_technique(tech)，其中tech是一个ExplorationTechnique的子类实例，angr.exploration_techniques可以看到angr内置的探索技术</p>
<h2 id="Execution-Engines"><a href="#Execution-Engines" class="headerlink" title="Execution Engines"></a>Execution Engines</h2><h3 id="Breakpoints"><a href="#Breakpoints" class="headerlink" title="Breakpoints"></a>Breakpoints</h3><p>可以设置在执行到某一类操作时停止，比如内存读</p>
<h2 id="Analyses-1"><a href="#Analyses-1" class="headerlink" title="Analyses"></a>Analyses</h2><p>内置的分析</p>

	
	</div>
  <a type="button" href="/2022/11/04/angr/#more" class="btn btn-default more">阅读此文</a>
</div>

           
		
           
			  
	
	<!-- display as entry -->	
		<h3 class="title">
			<div class="date"> 2022-10-27 </div>
			<div class="article-title"><a href="/2022/10/27/Symbolic-Execution-Tech/" >Symbolic Execution Tech</a></div>						
		</h3>
	


			  <div class="entry">
  <div class="row">
	
	
		<h1 id="A-Survey-of-Symbolic-Execution-Tech"><a href="#A-Survey-of-Symbolic-Execution-Tech" class="headerlink" title="A Survey of Symbolic Execution Tech"></a>A Survey of Symbolic Execution Tech</h1><h2 id="Author"><a href="#Author" class="headerlink" title="Author"></a>Author</h2><p>Roberto Baldoni, Emilio Coppa, Daniele Cono D’elia, Camil Demetrescu, and Irene Finocchi<br>Sapienza University of Rome</p>
<h2 id="Background"><a href="#Background" class="headerlink" title="Background"></a>Background</h2><p>The key idea is to allow a program to take on <em>symbolic</em>-rather than <em>concrete</em>-input values.<br>Execution is performed by a symbolic execution engine.<br>It maintains for each explored control flow path:</p>
<p>(1) a first-order Boolean <em>formula</em> that describes the conditions satisfied by the branches taken along that path,</p>
<p>(2) a <em>symbolic memory store</em> that maps variables to symbolic expressions or values.</p>
<p>Evert value that cannot be determined by a static analysis of the code, such as an <strong>actual parameter</strong> of a function or the <strong>result of a system call</strong> that reads data from a stream, is <strong>represented by a symbol $\alpha_i$</strong>.</p>
<h4 id="At-any-time-the-symbolic-execution-engine-maintains-a-state-stmt-sigma-pi-where"><a href="#At-any-time-the-symbolic-execution-engine-maintains-a-state-stmt-sigma-pi-where" class="headerlink" title="At any time, the symbolic execution engine maintains a state $(stmt, \sigma, \pi)$ where:"></a>At any time, the symbolic execution engine maintains a state $(stmt, \sigma, \pi)$ where:</h4><ul>
<li><p><em>stmt</em> is the next statement to evaluate. It can be an assignment, a conditional branch, or a jump.</p>
</li>
<li><p>$\sigma$ is a symbolic store that associates program variables with either expressions over concreate values or symbolic values $ \alpha_i $.</p>
</li>
<li><p>$\pi$ denotes the <strong>path constraints</strong>, i.e., is a formula that expresses a set of assumptions on the symbols $\alpha_i$ due to branches taken in the execution execution to reach <em>stmt</em>. At the beginning of the analysis, $\pi = true$.</p>
</li>
</ul>
<h4 id="Depending-on-stmt-the-symbolic-engine-changes-the-state-as-follows"><a href="#Depending-on-stmt-the-symbolic-engine-changes-the-state-as-follows" class="headerlink" title="Depending on stmt, the symbolic engine changes the state as follows:"></a>Depending on <em>stmt</em>, the symbolic engine changes the state as follows:</h4><ul>
<li><p>The evaluation of an assignment $x=e$ updates the symbolic store $\sigma$ by associating x with a new symbolic expression $e_s$.</p>
</li>
<li><p>The evaluation of a conditional branch if $e$ then $s_true$ else $s_false$ affects the path constraints $\pi$.</p>
</li>
<li><p>The evaluation of a jump <em>goto s</em> updates the execution state by advancing the symbolic execution to statement <em>s</em>.</p>
</li>
</ul>
<h4 id="Challenges-in-Symbolic-Execution"><a href="#Challenges-in-Symbolic-Execution" class="headerlink" title="Challenges in Symbolic Execution"></a>Challenges in Symbolic Execution</h4><ul>
<li><p>Memory: pointers, arrays and other complex objects?</p>
</li>
<li><p>Enviroment: interactions across software stacks?</p>
</li>
<li><p>State space explosion: path explosion?</p>
</li>
<li><p>Constraint solving: in practice?</p>
</li>
</ul>
<h2 id="Symbolic-Execution-Engines"><a href="#Symbolic-Execution-Engines" class="headerlink" title="Symbolic Execution Engines"></a>Symbolic Execution Engines</h2><p>important principles for the design of symbolic executors</p>
<h4 id="Mixing-Symbolic-and-Concrete-Execution-Concolic"><a href="#Mixing-Symbolic-and-Concrete-Execution-Concolic" class="headerlink" title="Mixing Symbolic and Concrete Execution (Concolic)"></a>Mixing Symbolic and Concrete Execution (Concolic)</h4><ul>
<li><p><strong>Main limitation of classical symbolic execution.</strong> It cannot explore feasible executions that would  result in path constraints that cannot be dealt with. For example, external code not traceable by the executor, complex constraints involving (e.g., non-linear arithmetic or transcendental functions)</p>
</li>
<li><p><strong>Dynamic Symbolic Execution.</strong> the execution engine maintains a concrete store $\sigma_c$. As a consequence, the symbolic engine does not need to invoke the constraint solver to decide whether a branch condition is (un)satisfiable: this is directly tested by the concrete execution.</p>
</li>
<li><p><strong>Selective Symbolic Execution.</strong> one might want to explore only some components of a software stack in full, not caring about others.</p>
</li>
</ul>

	
	</div>
  <a type="button" href="/2022/10/27/Symbolic-Execution-Tech/#more" class="btn btn-default more">阅读此文</a>
</div>

           
		
           
			  
	
	<!-- display as entry -->	
		<h3 class="title">
			<div class="date"> 2022-10-25 </div>
			<div class="article-title"><a href="/2022/10/25/Decompiling-x86-Deep-Neural-Network-Executables/" >Decompiling x86 Deep Neural Network Executables</a></div>						
		</h3>
	


			  <div class="entry">
  <div class="row">
	
	
		<h1 id="Decompiling-x86-Deep-Neural-Network-Executables"><a href="#Decompiling-x86-Deep-Neural-Network-Executables" class="headerlink" title="Decompiling x86 Deep Neural Network Executables"></a>Decompiling x86 Deep Neural Network Executables</h1><p>Zhibo Liu, The Hong Kong University of Science and Technology</p>
<h2 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h2><p>They present BTD (Bin to DNN), a decompiler for DNN executables. BTD takes DNN executables and outputs full model specifications, including types of DNN operators, network topology, dimensions, and parameters that are (nearly) identical to those of the input models. <strong>Supports different DL compilers and with full optimizations enabled on x86 platforms.</strong></p>
<p><strong>Employs learning-based techniques to infer DNN operators, dynamic analysis to reveal network architectures, and symbolic execution to facilitate inferring dimensions and parameters of DNN operators.</strong></p>
<p>BTD enables accurate recovery of full specifications of complex DNNs with millions of parameters (e.g., ResNet). The recivered DNN specifications can be re-compiled into a new DNN executable exhibiting identical behavior to the input executable.</p>
<p>They also demonstrate cross-architecture legacy code reuse using BTD, and envision BTD being used for other critical downstream tasks like DNN security hardening and patching.</p>
<h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><p>A DL compiler takes a high-level model specification (e.g., in ONNX format) and generates corresponding low-level optimized binary code for a variety of hardware backends (from cloud servers to embedded devices, GPUs, CPUs, and FPGAs).</p>
<p>Compilation of high-level models into binary code typically involves multiple optimization cycles. DL compiler can optimize code utilizing domain-specific hardware features and abstractions. However, they observe that different low-level representaions of the same DNN operator in executables generally retain invariant high-level semantics, as DNN operators like ReLU and Sigmoid, are mathematically defined in a rigorous manner.</p>
<p>They proposed a three-step approach for full recovery of DNN operators, network topology, dimensions, and parameters.</p>
<ul>
<li>BTD conducts representation learning over disassembler-emitted assembly code to classify assembly functions as DNN operators, such as convolution layers (Conv).</li>
<li>Dynamic analysis is then used to chain DNN operators together, thus recovering their topological connectivity.</li>
<li><p>To further recover dimensions and parameters of certain DNN operators (e.g., Conv), they launch trace-based symbolic execution to generate symbolic constraints, primarily over floating-point-related computations. The human-readable symbolic constraints denote semantics of corresponding DNN operators that are invariant across different compilation settings. To deliver an automated pipeline, they then define patterns over symbolic constraints to automatically recover dimensions and memory layouts of parameters. They incorporate taint analysis to largely reduce the cost of symbolic execution which is more heavy weight.</p>
</li>
<li><p>BTD is scalable to recover DNN models from 65 DNN executables, including nearly 3 million instructions, in 60 hours with negligible errors.</p>
</li>
<li><p>Moreover, to demonstrate BTD’s correctness, they rebuild decompiled model specifications with PyTroch. The results show that almost all decompiled DNN models can be recompiled into new executables that behave identically to the reference executables. </p>
</li>
</ul>
<h2 id="Preliminary"><a href="#Preliminary" class="headerlink" title="Preliminary"></a>Preliminary</h2><p><strong>DNN Compiler Frontend: Graph IRs and Optimizations.</strong> Convert DNN computation graphs into graph IRs. Graph IRs specify high-level inputs and outputs of each operator, but do not restrict how each operator is implemented.<br>Transformation and optimization of computation grpahs (IRs).</p>
<p><strong>DNN Compiler Backend: Low-Level IRs and Optimizations.</strong> Graph IR operators can be converted into low-level linear algebra operators. For example, a fully connected (FC) operator can be representated as matrix multiplication followed be addition. Low-level IRs are usually memory related. Hence, optimizations at this step can include hardware intrinsic (固有的) mapping, memory allocation, loop-related optimizations, and parallelization.<br>Transformation and optimization of low-level linear algebra operators.</p>
<p><strong>DNN Compiler Backend: Scheduling and Tuning.</strong> Policies mapping an operator to low-level code are called <em>schedules</em>. </p>
<p><strong>DNN Compiler Backend: Code Gen.</strong> When generating machine code, a DNN operator (or several fused operators) is typically compiled into an individual assembly function. </p>
<h2 id="Decompiling-DNN-Executables"><a href="#Decompiling-DNN-Executables" class="headerlink" title="Decompiling DNN Executables"></a>Decompiling DNN Executables</h2><p><strong>Definition.</strong> The full specifications include: (1) DNN operators(e.g., ReLU, Pooling, and Conv) and their topological connectivity, (2) dimensions of each DNN operator, such as #channels in Conv, and (3) parameters of each DNN operator, such as weights and biases, which are important configurations learned during model training.</p>
<p><strong>Comparison with C/C++ Decompilation.</strong></p>
<ul>
<li>Statements vs. Higher-Level Semantics: Software decompilation line-by-line translates machine instructions into C/C++ statements. </li>
<li>Common Uncertainty: There is no fixed mapping between C/C++ statements and assembly instructions. DL compilers may adopt different optimizations for compiling the same DNN operators. The compiled code may exhibit distinct syntactic forms. Nevertheless, the semantics of DNN operators are retained.</li>
<li>End Goal: Software decompilation is fundamentally undecidable, and decompiled C/C++ code mainly aids (human-based) analysis and comprehension, not recompilation. Besides helping (human-based) comprehension, BTD boosts model reuse, migration, security hardening, and adversarial attacks.</li>
</ul>
<p>NN的反编译主要是一个分类问题，C/C++的反编译是生成问题。 </p>
<p><strong>Opacity in DNN Executables.</strong> </p>
<p>Different compilers and optimizations can result in complex and distinct machine code realizations. </p>
<p><strong>Design Focus.</strong> BTD is designed to process common DNN models compiled by standard DL compilers. </p>
<h2 id="Design"><a href="#Design" class="headerlink" title="Design"></a>Design</h2><p>Deduce high-level model specifications from low-level instructions. </p>
<p>We advocate DL decompilers to satisfy the following criteria:</p>
<ul>
<li><strong>R1 (Generalizability):</strong> Avoid brittle assumptions. Generalize across compilers, optimizations, and versions.</li>
<li><strong>R2 (Correctness):</strong> Use effective, resilient methods and produce correct outputs.</li>
<li><strong>R3 (Performance):</strong> Be efficient when necessary.</li>
<li><strong>R4 (Automation):</strong> Avoid manual analysis and automate the decompilation process.</li>
</ul>
<h4 id="Workflow"><a href="#Workflow" class="headerlink" title="Workflow"></a>Workflow</h4><p>(1) Learning-based techniques for recognizing assembly function as DNN operators like Conv.</p>
<p>(2) Reconstruct the network topology using dynamic analysis.</p>
<p>(3) Use trace-based symbolic execution to extract operator semantics from assembly code and then recover dimensions and parameters with semantics-based patterns. Some operators are too costly for symbolic execution to analyze. They use taint analysis to keep only tainted sub-traces for more expensive symbolic execution to analyze.</p>
<p>(4) BTD produces model specifications that behave identically to original models. BTD does not guarantee 100% correct outputs. Procedures users can follow to fix errors.</p>
<ul>
<li><p><strong>Type I</strong> operators, including activation functions like ReLU and element-wise arithmetic operators, do not ship with parameters; recovering their dimensions is trivial.</p>
</li>
<li><p><strong>Type II and III</strong> operators require dimensions or parameters, such as Polling’s stride <em>S</em> and kernel size <em>K</em>.</p>
</li>
<li><p><strong>Type IV</strong> operators require both parameters and dimensions.</p>
</li>
</ul>
<p><strong>Compilation Provenance.</strong> (1) which DL compiler is used, and (2) whether e is compiled with full optimization -O3 or no optimization -O0. The authors extend their learning-based method to predict compilation provenance from assembly code.</p>
<p>Some patterns are designed separately for Glow- and TVM-emitted executables.</p>
<h3 id="DNN-Operator-Recovery"><a href="#DNN-Operator-Recovery" class="headerlink" title="DNN Operator Recovery"></a>DNN Operator Recovery</h3><p>Train a neural model to map assembly functions to DNN operators. Use representation learning and treat x86 opcodes as language tokens.</p>
<p><strong>Atomic OPs.</strong> Define atomic OPs over x86 opcodes. Each opcode is thus split into atomic OPs. Use atomic OP sequences represent a DNN operator.</p>
<p><strong>Dividing Opcodes into Atomic OPs.</strong> BPE. They split each opcode into a sequence of characters and counted consecutive characters to find the most frequent ones.</p>
<p><strong>Learning over Atomic OPs.</strong> Train a neural identifier model with a sequence of atomic OPs from an assembly function as inputs. The model outputs a 1D vector with N dimensions (N is the total number of unique DNN operators), where multiple “1” in the vector implies that this assembly function represents several fused DNN operators (融合算子). </p>
<p><strong>From Operators to Compilation Provenance.</strong> 直接使用之前的函数的embeddings分类，认为这个任务很简单</p>
<h3 id="DNN-Network-Topology-Recovery"><a href="#DNN-Network-Topology-Recovery" class="headerlink" title="DNN Network Topology Recovery"></a>DNN Network Topology Recovery</h3><p>A DNN operator has a fixed number of inputs and outputs. Use Intel Pin, a dynamic instrucmentation tool, to hook every callsite. Record the memory addresses of inputs/outputs passed to callsites and connect two operators if the successor’s inputs match the predecessor’s outputs.</p>
<p>This step does not rely on any compiler-specific assumptions, however, dynamic analysis is needed. (Intel Pin 也局限了使用的平台，其他架构或许没有这种工具或者无法监控内存，动态分析开销也比较大）</p>
<p>This dynamic analysis is not limited by “coverage”. （存在疑问，依赖于DNN编译器的先验知识）</p>
<h3 id="Dimension-and-Parameter-Recovery"><a href="#Dimension-and-Parameter-Recovery" class="headerlink" title="Dimension and Parameter Recovery"></a>Dimension and Parameter Recovery</h3><p>Inputs and parameters are typically stored separately in memory, whereas neighbor input/parameter elements are stored contiguously. （存在疑问，是栈空间还是堆空间，连续可能是偶然的）</p>
<p><strong>General Workflow.</strong> summarize operator invariant semantics with symbolic execution.</p>
<p>(1) log execution traces and use taint analysis to shroten the traces.</p>
<p>(2) use symbolic execution to summarize the input-output constraint of each assembly function.</p>
<p>(3) infer dimensions using patterns defined over constraints and futher extract parameters.</p>
<h4 id="Trace-Logging-and-Taint-Analysis"><a href="#Trace-Logging-and-Taint-Analysis" class="headerlink" title="Trace Logging and Taint Analysis"></a>Trace Logging and Taint Analysis</h4><p>Use Intel Pin to log the execution trace of an operator’s assembly function.</p>
<p><strong>Pin takes several hours to log one trace.</strong></p>
<p>Hence, analyzing a subtrace containing one iteration of the outermost loop is sufficient (as long as a complete calculation of an output element is reflected in this subtrace).</p>
<p><strong>Taint Analysis.</strong> Use backward taint analysis to rule out instructions that are not involved in computing outputs.</p>
<p>Trace logging records each instructions’s execution context, including concrete memory address values. For each memory acess during taint propagation, they compute concrete addresses to taint/untaint memory cells accordingly.</p>
<h4 id="Symbolic-Execution"><a href="#Symbolic-Execution" class="headerlink" title="Symbolic Execution"></a>Symbolic Execution</h4><p>Launch SE over tainted x86 instructions.</p>
<p><strong>Identifying Memory Layouts.</strong> 建立了一个表，对应每个算子传入的参数应该是inputs还是parameters，还是outputs. Then collect and identify inputs and parameters’ memory addresses by querying the configuration. Identify memory addresses and classify them into weights and inputs. Cluster all addresses of the same parameter to scope that parameter’s memory region (i.e., the starting address and size).</p>
<h4 id="Dimension-Recovery"><a href="#Dimension-Recovery" class="headerlink" title="Dimension Recovery"></a>Dimension Recovery</h4><p>Conv operator</p>
<p><strong>Kernel Size K, Input Channel $I_C$, Zero Padding P.</strong> </p>
<p><strong>Output Channels $O_C$.</strong><br>这一部分需要了解相关函数的参数所代表的含义，根据内存大小和布局推测这几个要素。</p>
<h4 id="Recover-Parameters"><a href="#Recover-Parameters" class="headerlink" title="Recover Parameters"></a>Recover Parameters</h4><p>Idenfity their starting addresses and memory layouts.<br>识别存储参数的内存区域。<br>Use Pin to dump parameters to disk at runtime.<br>同样依赖于运行时。</p>
<p><strong>Handling Compiler Optimizations.</strong> SSE parallelism by reading 4 (or 8) floating numbers from contiguous memory into one register. These modify Conv’s standard memory layout, impeding parameter recovery. Similar to dimension inference, they use patterns to identify optimized layouts. </p>
<h3 id="Executables-Emitted-by-NNFusion"><a href="#Executables-Emitted-by-NNFusion" class="headerlink" title="Executables Emitted by NNFusion"></a>Executables Emitted by NNFusion</h3><p>Some DL compilers generate executables statically linked with kernel libraries.</p>
<p>It is easier to decompile NNFusion- and XLA-emitted executables since they contain warpper function to invoke target operator implementations in kernel libraries. </p>
<p>运行时，通过Pin恢复网络拓扑和劫持通过warpper发送的数据。劫持的数据包括dimensions和指向参数的pointers. 然后从内存中获取参数。</p>
<h2 id="Evaluation"><a href="#Evaluation" class="headerlink" title="Evaluation"></a>Evaluation</h2><p><strong>RQ1 (Comprehensiveness and Correctness):</strong> Is BTD comprehensive and correct to process all operators used in common DL models compiled with <strong>different compilers</strong> and <strong>optimization options</strong>?</p>
<ul>
<li><p>Predicting DNN Operator Type: Glow has 14 types and TVM has 30. </p>
</li>
<li><p>数据偏差：基于统计分布的模型仍然会考虑到某一操作经常出现在另一操作之后使得分类结果偏向于出现概率大的类别，从而产生错误。</p>
</li>
<li><p>具有相似汇编代码的操作：也会存在误分类</p>
</li>
<li><p><strong>DNN Network Topology Recovery:</strong> compare the recovered network topology with the reference DNN’s computation graphs.</p>
</li>
<li><p><strong>Parameter and Dimension Recovery:</strong> Except for TVM -O0, it is difficult to compare the recovered dimensions/parameters with the reference due to compiler optimization.</p>
</li>
<li><p><strong>Recompilation</strong> They re-implement DNN models in PyTorch using recovered DNN models, then export models as ONNX files and compiled into DNN executables using the same compilation provenance.<br>compare the predicted labels and confidence scores yielded by recompiled and reference executables over every input from validation dataset.</p>
</li>
<li><p><strong>Decompiling NNFusion Outputs</strong> </p>
</li>
<li><p><strong>Other Models</strong> NLP Models, Audio Processing Models.</p>
</li>
</ul>
<p><strong>RQ2 (Robutness):</strong> Is BTD robust to survive frequent DL compiler implementation changes?</p>
<p>Evaluated BTD with prior versions of DL compilers released in the past two years.</p>
<p>BTD is robust enough against changes in current and prior versions of DL compilers. We anticipate that compiler changes are unlikely to affect the robustness of BTD in the near future.</p>
<p><strong>RQ3 (Extensibility):</strong> Can BTD be easily extended to support new operators and models? What efforts are needed?</p>
<p>Recovery of parameters/dimensions of complex operator. Supporting a new operator may need new or existing patterns. Symbolic constraints are generally human readable. We typically need several hours to desion and validate a new pattern for operators without complex optimization.</p>
<p>Users experienced in DL models can spend reasonable effort to add support for new operators and models by modifying existing patterns in BTD.</p>
<p><strong>RQ4 (Error Fixing):</strong> How does BTD handle decompilation errors?</p>
<p>On one hand, with rules presented in Sec. 6, BTD can detect and automatically fix the errors exposed when decompiling the ResNet18 executable.</p>
<p>To cope with decompilation defects, BTD provides error detection &amp; automated fixing mechanism, including a collection of rules derived from domain-specific knowledge and observations.</p>
<h2 id="Discussion"><a href="#Discussion" class="headerlink" title="Discussion"></a>Discussion</h2><p>DL compilers produce distinct executables on GPUs and CPUs. For example, TVM creates a standalone DNN executable on CPU, but a runtime library, including detailed model information, and an OpenCL/CUDA executable on GPU.</p>

	
	</div>
  <a type="button" href="/2022/10/25/Decompiling-x86-Deep-Neural-Network-Executables/#more" class="btn btn-default more">阅读此文</a>
</div>

           
		
           
			  
	
	<!-- display as entry -->	
		<h3 class="title">
			<div class="date"> 2022-10-21 </div>
			<div class="article-title"><a href="/2022/10/21/NeurDP/" >NeurDP</a></div>						
		</h3>
	


			  <div class="entry">
  <div class="row">
	
	
		<h2 id="研究背景"><a href="#研究背景" class="headerlink" title="研究背景"></a>研究背景</h2><p>近年来，神经网络在代码理解和逆向工程领域取得了广泛的应用。一些工作，例如著名的Github Copilot和CodeBERT等使用神经网络来学习源码的表示，在代码生成、补全和注释生成等方面取得了较好的效果。同样的，许多工作研究神经网络在二进制或汇编代码理解中的利用，从而帮助分析人员进行反汇编、恶意代码检测等。神经网络在程序分析和逆向工程中的应用大幅度帮助分析人员节省了时间成本。并且，和传统的方法相比，其速度通常较快，在有GPU的条件下可以很好的和下游任务模型进行结合，实现大批量快速的逆向工程和程序分析。</p>
<p>反编译器是逆向工程和程序分析中常用的工具，对于漏洞发现和恶意代码分析有重要作用。反编译过程可以看作是将低级程序语言翻译到和它功能等价的高级程序语言的过程。传统的反编译器的开发需要很多逆向工程师总结其程序分析经验，将其制定成规则，并结合程序分析技术来实现。著名的开源反编译器RetDec有上百个开发者曾为其贡献代码，并且开发多年，至今仍然不完善。</p>
<p>机器翻译模型在自然语言翻译的领域取得了重大进展。一些研究者受到自然语言翻译技术以及AI在代码领域中的发展的启发，开始探索使用端到端的机器翻译模型来将低级程序语言翻译成高级程序语言。这些方法尽管对于输入和输出进行了各种预处理，设计了各种模型结构，但是他们仍然无法解决优化后二进制的反编译问题。</p>
<h2 id="研究困难"><a href="#研究困难" class="headerlink" title="研究困难"></a>研究困难</h2><p>编译器优化在真实的项目中是广泛使用的。常用的GCC和Clang编译器都是默认开启O1级别的优化。编译器常常是两段式的结构，分为前端和后端，分别进行机器无关的优化和机器相关的优化。经过对编译技术的分析和实验，我们发现训练一个能处理优化后二进制代码的端到端的反编译模型非常困难。因为模型常常是数据驱动的，训练代码翻译模型需要高质量的低级语言和高级语言代码对。然而由于编译器优化策略，优化后的低级语言和高级语言在文本所包含的信息上常常难以对应，并且其结构差异很大。已有的神经网络反编译方法在解决优化问题上主要存在两个难点：</p>
<p>1）编译优化策略通常大幅度改变源码的结构。这种修改不仅体现在指令类型等层面，更多的是结构上的改变，有一些优化策略甚至会提前对一些语句进行运算，预测其结果，例如常量传播。这种改变会导致源码中有很多冗余的文本，其语义在二进制代码中本身就不存在。端到端的训练需要学习优化策略，例如上文提到的算术运算，训练这样的模型是很困难的。</p>
<p>2）对低级程序语言（二进制文件）和高级程序语言（源码文件）进行划分，并形成准确的对应关系是不容易的。以往的工作通常使用函数或者基本块进行划分，但是函数和基本块内的语句数量是没有上限的，对于较大的基本块或函数，模型很难对其进行翻译。根据调试信息划分面临着和难点1一样的问题。而如果设置最大窗口顺序划分指令序列，又会面临对应不准确的问题。</p>
<h2 id="整体设计"><a href="#整体设计" class="headerlink" title="整体设计"></a>整体设计</h2><p>NeurDP主要解决当前基于神经网络的反编译方法无法解决优化后二进制反编译的问题。其中预处理部分对LPL进行一些静态分析，包括SSA形式转换，和一些简单的寄存器传播生成低级中间语言LIR。OTU是方法的核心部分，根据数据依赖关系将LIR和HIR划分为更小且可以准确匹配的代码片段。HIR是基于LLVM IR简化版本的高级中间语言。NeurDP模型部分使用图神经网络GNN学习LIR的数据依赖图，并生成HIR指令序列。HIR Generation对生成的指令序列操作数进行识别和填充。最终，结合函数的参数、返回值以及控制结构，并使用规则将HIR转换为HPL，从而生成高级语言函数。</p>
<p><img src="NeurDP-overview.jpg" alt=""></p>
<p>为了解决困难1，本方法使用中间表示IR作为连接LPL和HPL的桥梁。IR经过了编译器前端优化，因此其文本上包含的信息和结构与LPL更加的接近。而从IR到HPL通过制定规则可以很容易实现。因此，我们选择用模型去完成从LPL到IR的翻译。</p>
<p>为了解决困难2，本方法设计了一种基于数据依赖图的切分方式，将基本块切分成更小的代码片段。基于我们的分析，绝大多数的优化策略都是基于数据流分析的。优化策略通常不会改变基本块的输入和输出的对应关系。两个不同输出在数据依赖图中的子图存在重叠部分和独立部分。考虑到对一个输出的优化不能对另一个输出的结果产生影响，优化往往是在这些重叠或独立部分的内部发生的。因此，这些子图在HIR和LIR中可以较准确地进行对应。我们按照这个原则对LIR和HIR的基本块进行划分，获得更细粒度且对应准确的LIR-HIR代码片段对作为训练集。</p>
<h2 id="实验效果"><a href="#实验效果" class="headerlink" title="实验效果"></a>实验效果</h2><p>我们测试了其他网络在使用源码，AST和IR时代码翻译的表现和NeurDP进行对比，结果如下表。可以看到使用IR之后普通的序列模型准确率也有大幅度地提升。NeurDP使用图神经网络对输入进行编码，效果比其他序列模型更好。</p>
<p><img src="NeurDP-Table6.jpg" alt=""></p>
<p>我们测试了使用不同的基本块切分方式的代码翻译的表现，结果如下图，可以看到基于数据流的划分方式比顺序滑动窗口效果明显提升。而使用我们的OTU比普通的数据流的窗口效果更好。</p>
<p><img src="NeurDP-Table5.jpg" alt=""></p>
<p>为了验证NeurDP对优化后代码的处理能力，我们将他与其他两个神经网络反编译工作Neutron和Coda以及著名的开源反编译工具RetDec在clang的O0-O3优化级别下的准确率进行了对比，结果如下表。可以看到NeurDP效果比其他工具都好，并且对于不同优化级别的代码，NeurDP的表现差异较小。RetDec由于其功能还不完善，出现了很多函数无法识别的错误。</p>
<p><img src="NeurDP-Table4.jpg" alt=""></p>
<p>Strip是一个从二进制中去掉调试和符号信息的工具，会增加反编译的难度。我们对比了在保留所有调试和符号信息、去掉调试信息和去掉所有调试和符号信息的条件下，NeurDP在O0-O3三个优化级别上的表现。结果如下表，可以看到NeurDP在去掉符号信息的情况下也表现良好。</p>
<p>我们测试使用的数据集公开在了<a target="_blank" rel="noopener" href="https://github.com/zijiancogito/neur-dp-data">https://github.com/zijiancogito/neur-dp-data</a> 。</p>

	
	</div>
  <a type="button" href="/2022/10/21/NeurDP/#more" class="btn btn-default more">阅读此文</a>
</div>

           
		
           
			  
	
	<!-- display as entry -->	
		<h3 class="title">
			<div class="date"> 2022-10-21 </div>
			<div class="article-title"><a href="/2022/10/21/DnD-A-Cross-Architecture-Deep-Neural-Network-Decompiler/" >DnD: A Cross-Architecture Deep Neural Network Decompiler</a></div>						
		</h3>
	


			  <div class="entry">
  <div class="row">
	
	
		<h1 id="DnD-A-Cross-Architecture-Deep-Neural-Network-Decompiler"><a href="#DnD-A-Cross-Architecture-Deep-Neural-Network-Decompiler" class="headerlink" title="DnD: A Cross-Architecture Deep Neural Network Decompiler"></a>DnD: A Cross-Architecture Deep Neural Network Decompiler</h1><p>Ruoyu Wu, Purdue University</p>
<h2 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h2><p>This paper proposes DnD, the first compiler and ISA-agnostic DNN decompiler.<br>It aims to lift the binary code compiled from a DNN on <strong>edge-device</strong> to a novel intermediate representation, able to express the high-level mathematical DNN operations.<br>They evaluate DnD on two compilers (<strong>Glow and TVM</strong>) and three ISAs (<strong>Thump, AArch64, and x86-64</strong>).<br>Dnd enables extracting the DNN models used by real-wrold micro-controllers and attacking them using white-box adversarial machine learning techniques.</p>
<h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><ul>
<li><p>Traditional decompilers cannot capture the mathematical semantics of compiled DNN models.</p>
</li>
<li><p>DnD works with a compiled DNN model and recover its parameters, hyper-parameters and topology, and express the decompiled model in a high-level representation, encoded in the ONNX modeling language.</p>
</li>
<li><p>Techniques: 1. Uses <strong>symboloc execution</strong> in conjunction with a dedicated loop analysis to capture precise mathematical formulas representing how different DNN operators process the received data. 2. Uses a novel IR to express the high-level mathematical DNN operations in a compiler- and ISA-agnostic way. 3. Identifies the type and location of the DNN operators in a target binary by matching the extracted mathematical operations with template mathematical DNN operations, recovering hyper-parameters and parameters of all the identified DNN operators, as well as the overall network topology.</p>
</li>
<li><p>The recovered DNN model can be used to boost adversarial attacks against the original DNN, enabling the usage of the white-box attacks, in place of less efficient black-box ones.</p>
</li>
<li><p>Contributions: design and implement DnD (including decompiling of stripped binaries), design IR</p>
</li>
<li><p>Artifacts: <a target="_blank" rel="noopener" href="https://github.com/purseclab/DnD">https://github.com/purseclab/DnD</a></p>
</li>
</ul>
<h2 id="Background-and-Motivation"><a href="#Background-and-Motivation" class="headerlink" title="Background and Motivation"></a>Background and Motivation</h2><ul>
<li><p>ONNX: the open standard for ML interoperability developed by Linux Foundation.</p>
</li>
<li><p>DNN Operators: the building blocks of DNNs. A DNN operator takes the output of previous operators as its input and computes its output based on its operator type and its parameters.(174 different DNN operators defined in ONNX).</p>
</li>
<li><p>DNN Hyper-parameters and Parameters: (1) the algorithm hyper-parameters: only used during the training phase (2) the model hyper-parameters: define the netwrok structure and how the operators function (Total number of operators and the type of each operator. The DNN topology. The attributes of each operator that define its detailed semantics.)</p>
</li>
<li><p>DNN Compilers: Glow, TVM, XLA, NNFusion. Frontend-Backend component. </p>
</li>
<li><p>Frontend: transforms a DNN model into a high-level IR and performs hardware-independent optimizations, such as operator fusion.</p>
</li>
<li><p>Backend: transforms a high-level IR to a low-level IR and performs hardware-specific optimizations (vectorization and loop-related optimizations).</p>
</li>
<li><p>Compilation Scheme: interpreter-based and ahead-of-time(AOT) compilation schemes.</p>
</li>
<li><p>Interpreter-based: generate DNN binaries at runtime.They usually produce two artifacts: a DNN configuration file describing the DNN model and a runtime library that contains all the DNN operator implementations.</p>
</li>
<li><p>AOT: Specialize the operator implementation for the specific compiled operator instance’s context.</p>
</li>
<li><p>Glow and TVM: An application feeds the input data to this inference function and obtains the predicted label as output.</p>
</li>
</ul>
<h2 id="System-Design"><a href="#System-Design" class="headerlink" title="System Design"></a>System Design</h2><h4 id="Workflow"><a href="#Workflow" class="headerlink" title="Workflow."></a>Workflow.</h4><p>(1) <strong>DNN Operator Location Identification.</strong> Recovers the CFG and identifies the location of inference function and DNN operators from the input (stripped) DNN binary.</p>
<p>(2) <strong>Operator Symmary Generation.</strong> </p>
<ul>
<li>Conducts loop analysis to identify loops’ information. </li>
<li>Leverages loop’s information to perform selective symbolic execution that extracts the output of a DNN operator as symbolic expressions of its input and parameters, which capture the mathematical semantic of a DNN operator.</li>
<li>Lift the symbolic expressions to the operator symmary of a DNN operator in their IR format includes the ASTs and other information.</li>
<li>Generates template ASTs through the afore-mentioned operator summary generation.</li>
</ul>
<p>(3) DNN Model Lifting<br>Lifts each operator summary to a DNN operator and convert it to a high-level DNN representation (i.e., an ONNX model).</p>
<ul>
<li>Matches the AST in each operator summary with a template AST to determine its DNN operator type.</li>
<li>Recovers the DNN topology by identify the data dependencies between DNN operators.</li>
<li>Recovers each DNN operator’s attributes and parameters leveraging the identified DNN operator type and DNN topology, and converts the fully-recovered DNN model to an ONNX model.</li>
</ul>
<p>In summary, they first recover the functions and CFGs. Then, they identify the intresting functions (inference function and NN operators). Then, they extract the symbolic expressions by SSE and transform them to their IR. Then, they <strong>match the IR with their AST template and determines the NN operator type</strong>. Then, they <strong>recovers the topology by identifying the data dependencies between NN operators</strong>. Finally, they recovers each NN operator’s <strong>attributes and parameters</strong> using the operator type and topology and convert it to ONNX language.</p>
<h2 id="Evaluation"><a href="#Evaluation" class="headerlink" title="Evaluation"></a>Evaluation</h2><h4 id="Generality"><a href="#Generality" class="headerlink" title="Generality"></a>Generality</h4><p>How many commonly-used DNN operators and models can be suported.</p>
<p>Support 59 (84%) DNN operators.<br>Fully support 30 (81%) DNN models out of the collected 37 DNN models.</p>
<h4 id="Correctness-Accross-different-DNN-compilers-ISAs-and-DNN-models"><a href="#Correctness-Accross-different-DNN-compilers-ISAs-and-DNN-models" class="headerlink" title="Correctness Accross different DNN compilers, ISAs, and DNN models"></a>Correctness Accross different DNN compilers, ISAs, and DNN models</h4><p>Compare the model architecture (operators and topology) and inference results of original DNN models and decompiled DNN models.</p>
<p>-Models: MNIST, MobileNets v2, ResNet v1</p>
<ul>
<li><p>ISAs: Thumb, AArch64, x86-64</p>
</li>
<li><p>Decompiler: Glow, TVM</p>
</li>
</ul>
<p>Evaluated 15 DNN binaries in total.</p>
<p>没有说明测试的二进制是否是strip的</p>
<h2 id="Case-Study"><a href="#Case-Study" class="headerlink" title="Case Study"></a>Case Study</h2><ul>
<li>Extraction Attack</li>
<li>Boosting Adversarial Attacks</li>
</ul>
<h2 id="Discussion-and-Limitations"><a href="#Discussion-and-Limitations" class="headerlink" title="Discussion and Limitations"></a>Discussion and Limitations</h2><ul>
<li><p>Compilers (XLA, NNFusion) which generate DNN binaries linked with open-souce mathematical libraries to leverage the tensor operations of these libraries. To support these additional compilers, we will need to implement a dedicated analysis to identify these tensor-specific library functions. This analysis could take advantage of function matching approaches.</p>
</li>
<li><p>Decompiling Binary on DNN Acceleartors. GPUs, FPGAs have very diverse ISAs that are usually not supported by the general-purpose disassemblers and the symbolic execution framework. <strong>NVIDIA provides closed-source disassemblers cuobjdump and nvidiaasm</strong>, which translate the CUDA binary into SASS assembly code. However, most details of SASS assembly code are kept secret.</p>
</li>
</ul>
<h2 id="Related-Work"><a href="#Related-Work" class="headerlink" title="Related Work"></a>Related Work</h2><p>reverse engineering techniques targeting smart contract[1], control firmware[2] and Bluetooth firmware[3].</p>
<p>[1] Yi Zhou, Deepak Kumar, Surya Bakshi, Joshua Mason, Andrew Miller, and Michael Bailey. Erays: reverse engineering ethereum’s opaque smart contracts. In Proceedings of the USENIX Security Symposium (Usenix SEC), 2018.</p>
<p>[2] Taegyu Kim, Aolin Ding, Sriharsha Etigowni, Pengfei Sun, Jizhou Chen, Luis Garcia, Saman Zonouz, Dongyan Xu, and Dave (Jing) Tian. Reverse engineering and retroﬁtting robotic aerial vehicle control ﬁrmware using dispatch. In Proceedings of the ACM International Conference on Mobile Systems, Applications, and Services (MobiSys), 2022.</p>
<p>[3] Jianliang Wu, Ruoyu Wu, Daniele Antonioli, Mathias Payer, Nils Ole Tippenhauer, Dongyan Xu, Dave Jing Tian, and Antonio Bianchi. LIGHTBLUE: Automatic Proﬁle-Aware debloating of bluetooth stacks. In Proceedings of the USENIX Security Symposium (Usenix SEC), 2021.</p>

	
	</div>
  <a type="button" href="/2022/10/21/DnD-A-Cross-Architecture-Deep-Neural-Network-Decompiler/#more" class="btn btn-default more">阅读此文</a>
</div>

           
		
           
		

		</div>

		<!-- pagination -->
		<div>
  		<center>
		<div class="pagination">
<ul class="pagination">
	 
</ul>
</div>

  		</center>
		</div>

		
		
	</div> <!-- col-md-9 -->

	
		<div class="col-md-3">
	<div id="sidebar">
	
			
  <div id="site_search">
   <div class="form-group">
    <input type="text" id="local-search-input" name="q" results="0" placeholder="搜索" class="st-search-input st-default-search-input form-control"/>
   </div>  
  <div id="local-search-result"></div>
  </div>


		
			<div class="widget">
    
	    <h4 class="dsq-widget-title">最新留言</h4>
		<div id="recent-comments"></div>
		<script type="text/javascript">
		    getRecentCommentsList({
			   type: "github" ? "github" : "github",
			   user: "zijiancogito",
               repo: "comment",
               client_id: "b79cbe842579a612ed08",
               client_secret: "6585bb42b7c5b2fedf088cfce6b7e811f8803fe3",
			   count: "5" ? "5" : 5,
			   recent_comments_target: "#recent-comments"
			});
		</script>
	
</div>

		
			
	<div class="widget">
		<h4>分类</h4>
		<ul class="tag_box inline list-unstyled">
		
			<li><a href="/categories/骈文/最喜欢/">最喜欢<span>1</span></a></li>
		
			<li><a href="/categories/符号执行/">符号执行<span>1</span></a></li>
		
			<li><a href="/categories/编译/">编译<span>3</span></a></li>
		
			<li><a href="/categories/骈文/">骈文<span>1</span></a></li>
		
		</ul>
	</div>

		
			
	<div class="widget">
		<h4>标签云</h4>
		<ul class="tag_box inline list-unstyled">		
		
			<li><a href="/tags/Binary-Analysis/">Binary Analysis<span>1</span></a></li>
		
			<li><a href="/tags/Decompiliation/">Decompiliation<span>1</span></a></li>
		
			<li><a href="/tags/置顶/">置顶<span>1</span></a></li>
		
			<li><a href="/tags/NN-Decompiler/">NN Decompiler<span>2</span></a></li>
		
			<li><a href="/tags/Decompiler/">Decompiler<span>3</span></a></li>
		
			<li><a href="/tags/Symbolic-Execution/">Symbolic Execution<span>1</span></a></li>
		
		 
		</ul>
	</div>


		
			
<div class="widget">
  <h4>最新文章</h4>
  <ul class="entry list-unstyled">
    
      <li>
        <a href="/2022/11/04/angr/" ><i class="fa fa-file-o"></i>angr</a>
      </li>
    
      <li>
        <a href="/2022/10/27/Symbolic-Execution-Tech/" ><i class="fa fa-file-o"></i>Symbolic Execution Tech</a>
      </li>
    
      <li>
        <a href="/2022/10/25/Decompiling-x86-Deep-Neural-Network-Executables/" ><i class="fa fa-file-o"></i>Decompiling x86 Deep Neural...</a>
      </li>
    
      <li>
        <a href="/2022/10/21/NeurDP/" ><i class="fa fa-file-o"></i>NeurDP</a>
      </li>
    
      <li>
        <a href="/2022/10/21/DnD-A-Cross-Architecture-Deep-Neural-Network-Decompiler/" ><i class="fa fa-file-o"></i>DnD: A Cross-Architecture D...</a>
      </li>
    
  </ul>
</div>

		
			
<div class="widget">
	<h4>链接</h4>
	<ul class="blogroll list-unstyled">
	
		<li><i class="fa fa-github"></i><a href="http://www.github.com/zijiancogito" title="My Github account." target="_blank"]);">My Github</a></li>
	
	</ul>
</div>


		
	</div> <!-- sidebar -->
</div> <!-- col-md-3 -->

	
	
</div> <!-- row-fluid -->


    </div>
  </div>
  <div class="container-narrow">
    <footer> <p>
  &copy; 2022 Zijian
  
      with help from <a href="http://hexo.io/" target="_blank">Hexo</a> and <a href="http://getbootstrap.com/" target="_blank">Twitter Bootstrap</a>. Theme by <a target="_blank" rel="noopener" href="http://github.com/wzpan/hexo-theme-freemind/">Freemind</a>.    
</p> </footer>
  </div> <!-- container-narrow -->
  


  
<a id="gotop" href="#">   
  <span>▲</span> 
</a>

<script src="/js/jquery.imagesloaded.min.js"></script>
<script src="/js/gallery.js"></script>
<script src="/js/bootstrap.min.js"></script>
<script src="/js/main.js"></script>
<script src="/js/search.js"></script> 


<link rel="stylesheet" href="/fancybox/jquery.fancybox.css" media="screen" type="text/css">
<script src="/fancybox/jquery.fancybox.pack.js"></script>
<script type="text/javascript">
(function($){
  $('.fancybox').fancybox();
})(jQuery);
</script>



   <script type="text/javascript">      
     var search_path = "search.xml";
	 if (search_path.length == 0) {
	 	search_path = "search.xml";
	 }
	 var path = "/" + search_path;
     searchFunc(path, 'local-search-input', 'local-search-result');
   </script>


<!-- syntax highlighting -->

  <script>
  marked.setOptions({
    highlight: function (code, lang) {
        return hljs.highlightAuto(code).value;
    }
  });
  function Highlighting(){
    var markdowns = document.getElementsByClassName('markdown');
    for(var i=0;i<markdowns.length;i++){
        if(markdowns[i].innerHTML) markdowns[i].innerHTML =marked(markdowns[i].innerHTML);
    }
  }
  window.addEventListener('DOMContentLoaded', Highlighting, false);
  window.addEventListener('load', Highlighting, false);
  </script>


<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [ ["$","$"], ["\\(","\\)"] ],
            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'],
            processEscapes: true
        }
    });
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax();
        for (var i = 0; i < all.length; ++i)
            all[i].SourceElement().parentNode.className += ' has-jax';
    });
</script>

<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML"></script>


</body>
</html>